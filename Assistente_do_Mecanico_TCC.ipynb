{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EdmilsonSantana/llm-vehicle-repair/blob/main/Assistente_do_Mecanico_TCC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Xnc6MorKQkU",
        "outputId": "4059e8cc-8828-4c8a-d5cd-2e355f9ff9f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3w8ud4KIGwQ"
      },
      "source": [
        "## Scraping data from AutoZone"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1phBwMcaJ5Bj"
      },
      "source": [
        "First, let's extract the sitemap with all categories and article links available."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5V-HR4zPdhr",
        "outputId": "fa8fa6d7-e199-4466-d2fb-8e4d1557cabf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: google-colab-selenium[undetected] in /usr/local/lib/python3.10/dist-packages (1.0.12)\n",
            "Requirement already satisfied: selenium in /usr/local/lib/python3.10/dist-packages (from google-colab-selenium[undetected]) (4.18.1)\n",
            "Collecting undetected-chromedriver (from google-colab-selenium[undetected])\n",
            "  Downloading undetected-chromedriver-3.5.5.tar.gz (65 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.4/65.4 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: urllib3[socks]<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from selenium->google-colab-selenium[undetected]) (2.0.7)\n",
            "Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.10/dist-packages (from selenium->google-colab-selenium[undetected]) (0.25.0)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.10/dist-packages (from selenium->google-colab-selenium[undetected]) (0.11.1)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from selenium->google-colab-selenium[undetected]) (2024.2.2)\n",
            "Requirement already satisfied: typing_extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from selenium->google-colab-selenium[undetected]) (4.10.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from undetected-chromedriver->google-colab-selenium[undetected]) (2.31.0)\n",
            "Collecting websockets (from undetected-chromedriver->google-colab-selenium[undetected])\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium->google-colab-selenium[undetected]) (23.2.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium->google-colab-selenium[undetected]) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium->google-colab-selenium[undetected]) (3.6)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium->google-colab-selenium[undetected]) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium->google-colab-selenium[undetected]) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium->google-colab-selenium[undetected]) (1.2.0)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.10/dist-packages (from trio-websocket~=0.9->selenium->google-colab-selenium[undetected]) (1.2.0)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium->google-colab-selenium[undetected]) (1.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->undetected-chromedriver->google-colab-selenium[undetected]) (3.3.2)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium->google-colab-selenium[undetected]) (0.14.0)\n",
            "Building wheels for collected packages: undetected-chromedriver\n",
            "  Building wheel for undetected-chromedriver (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for undetected-chromedriver: filename=undetected_chromedriver-3.5.5-py3-none-any.whl size=47048 sha256=c5a5e7ffda07ac7ce894d640da8471aaa139dbc52983688b95c1ca830c4be2d1\n",
            "  Stored in directory: /root/.cache/pip/wheels/cf/a1/db/e1275b6f7259aacd6b045f8bfcb1fcbc93827a3916ba55d5b7\n",
            "Successfully built undetected-chromedriver\n",
            "Installing collected packages: websockets, undetected-chromedriver\n",
            "Successfully installed undetected-chromedriver-3.5.5 websockets-12.0\n"
          ]
        }
      ],
      "source": [
        "%pip install google-colab-selenium[undetected]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1Lv23iMJ2oV"
      },
      "outputs": [],
      "source": [
        "sitemap_url = 'https://www.autozone.com/diy/category-sitemap'\n",
        "base_dir = '/content/drive/MyDrive/Colab Notebooks/autozone_data'\n",
        "sitemap_file = f'{base_dir}/sitemap.json'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AiSf1SGhT1Cg"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import google_colab_selenium as gs\n",
        "import os\n",
        "import json\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WpSZDH45FwcM"
      },
      "outputs": [],
      "source": [
        "def extract_sitemap():\n",
        "  browser = gs.UndetectedChrome()\n",
        "  browser.get(sitemap_url)\n",
        "\n",
        "  category_sitemap_page = BeautifulSoup(browser.page_source)\n",
        "\n",
        "  category_links = category_sitemap_page.select('.az-category-pod')\n",
        "\n",
        "  sitemap = []\n",
        "\n",
        "  for link in category_links:\n",
        "      href = link['href']\n",
        "      title = link.select_one('.az-category-pod__title').text\n",
        "      sitemap.append(dict(href=href, title=title, articles=[]))\n",
        "\n",
        "  for item in sitemap:\n",
        "      browser.get(item['href'])\n",
        "\n",
        "      print(f\"Processing {item['href']}\")\n",
        "\n",
        "      category_page = BeautifulSoup(browser.page_source, features='lxml')\n",
        "\n",
        "      article_links = category_page.select('a.az-blog-pod')\n",
        "\n",
        "      for link in article_links:\n",
        "          href = link['href']\n",
        "          title = link.select_one('.az-blog-pod__title').text\n",
        "          description = link.select_one('.az-blog-pod__description').text\n",
        "          item['articles'].append(dict(href=href, title=title, description=description))\n",
        "\n",
        "  with open(sitemap_file, 'w') as fp:\n",
        "      json.dump(sitemap, fp)\n",
        "\n",
        "  browser.close()\n",
        "\n",
        "\n",
        "if (not os.path.exists(sitemap_file)):\n",
        "    extract_sitemap()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3uHY9DtTiaQ"
      },
      "source": [
        "We are going to extract the content from the articles found in AutoZone sitemap."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uHlhwY5RUgdV"
      },
      "outputs": [],
      "source": [
        "articles_file = f'{base_dir}/articles.json'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v90PQbMdIJIh"
      },
      "outputs": [],
      "source": [
        "def extract_fa_questions(page_content):\n",
        "   faq_section = page_content.select('div.schema-faq-section')\n",
        "\n",
        "   faq_questions = []\n",
        "   for faq in faq_section:\n",
        "      question = faq.select_one('strong').text\n",
        "      answer = faq.select_one('.schema-faq-answer').text\n",
        "      faq_questions.append(dict(question=question, answer=answer))\n",
        "\n",
        "   return faq_questions\n",
        "\n",
        "def remove_section(page_content, css_selector):\n",
        "   section = page_content.select_one(css_selector)\n",
        "   if section:\n",
        "      section.decompose()\n",
        "\n",
        "\n",
        "def extract_articles():\n",
        "   file = open(sitemap_file)\n",
        "   sitemap = json.load(file)\n",
        "   driver = gs.UndetectedChrome()\n",
        "   articles = []\n",
        "\n",
        "   for category in sitemap:\n",
        "      for article in category['articles']:\n",
        "         try:\n",
        "            href = article['href']\n",
        "            print(f\"Processing {href}\")\n",
        "\n",
        "            driver.get(href)\n",
        "\n",
        "            article_page = BeautifulSoup(driver.page_source, 'html.parser')\n",
        "\n",
        "            page_content = article_page.select_one('#az-blog-content')\n",
        "\n",
        "            fa_questions = extract_fa_questions(page_content)\n",
        "\n",
        "            # Removing unwanted sections\n",
        "            remove_section(page_content, '.az-blog-post-section')\n",
        "            remove_section(page_content, '.az-blog-content__products')\n",
        "            remove_section(page_content, '.schema-faq')\n",
        "            remove_section(page_content, '#faq-people-also-ask')\n",
        "\n",
        "            # Removing Autozone ADs\n",
        "            autozone_ads = page_content.find(lambda tag: tag.name == \"p\" and \"autozone\" in tag.text.lower())\n",
        "            if (autozone_ads):\n",
        "               autozone_ads.decompose()\n",
        "\n",
        "            text_content = re.sub(r'\\n\\s*\\n', '\\n\\n', page_content.text.strip())\n",
        "            articles.append(dict(title=article['title'], content=text_content, category=category['title']))\n",
        "         except Exception as error:\n",
        "            print(f'Failed to extract {href}', error)\n",
        "\n",
        "   with open(articles_file, 'w') as fp:\n",
        "      json.dump(articles, fp)\n",
        "\n",
        "   driver.close()\n",
        "\n",
        "\n",
        "if (not os.path.exists(articles_file)):\n",
        "    extract_articles()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_ovldOBVDQh"
      },
      "source": [
        "## txtinstruct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "thuR9tkNUq_y"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install git+https://github.com/neuml/txtai git+https://github.com/neuml/txtinstruct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SsaMpDQiiMqM"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "mount_file_id": "1jdzFQfBomK42CMq2RKVQvVgfODSCiACc",
      "authorship_tag": "ABX9TyPAuhOs6LqPlTbKAiCb1/PW",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}