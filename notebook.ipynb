{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/EdmilsonSantana/llm-vehicle-repair/blob/main/Assistente_do_Mecanico_TCC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install selenium beautifulsoup4 datasets transformers[torch] deep-translator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y3w8ud4KIGwQ"
   },
   "source": [
    "## Scraping data from AutoZone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1phBwMcaJ5Bj"
   },
   "source": [
    "We are going to extract the content from the articles found in AutoZone sitemap and finetune the Flan-T5 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "H1Lv23iMJ2oV"
   },
   "outputs": [],
   "source": [
    "from articles import extract_articles\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "AiSf1SGhT1Cg"
   },
   "outputs": [],
   "source": [
    "articles = extract_articles(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "WpSZDH45FwcM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'Car AC Blowing Hot Air', 'content': \"Understanding the Causes\\n\\nA quick understanding of how air conditioning works can help with understanding what the causes could be. When AC is turned on, refrigerant that flows through the system absorbs heat from your vehicle's cabin where it's removed and, through a series of parts and processes, the heat is released into the atmosphere before circulating back and repeating the process. There are several points where something can be wrong, causing warm air rather than cool:\\n\\nThere isn't sufficient airflow in the cabin. This could be a problem with a bad blower motor, but more commonly a plugged cabin air filter is the culprit.\\nThere isn't enough refrigerant. The gas that circulates through the system can leak out, preventing it from working efficiently.\\nThe compressor may not be cycling. A clutch issue or a compressor failure can prevent the AC system from being able to disperse the heat the refrigerant has absorbed.\\nThe expansion valve is clogged. A blockage in the expansion valve could mean cooled refrigerant can't circulate back to the cabin.\\nThe radiator is blocked. Debris blocking the condenser, mounted behind the radiator, could make it impossible for the heated refrigerant to cool effectively.\\nThere's an electrical issue. A number of electrical connections could be loose or damaged, or a part like the HVAC control may not be working well.\\n\\nIf the air from the vents is blowing cool but not cold air, the airflow is weak, the vent temperature goes from hot to cold frequently, or you're only getting warm air from the vents, it's time to give your AC some attention.\\n\\nDIY Diagnosis and Quick Fixes\\n\\nMany AC problems can be identified on your own, and some can be remedied with a quick fix.\\n\\nFirst, check the cabin air filter condition and replace it if it's dirty or clogged.\\nCheck that the heater fan is blowing. If it's only blowing on high speed, the blower motor resistor might be faulty or a fuse might be blown.\\nClean off the radiator. If it's plugged with debris like leaves, dirt, and bugs, wash it off to allow air to pass through it and the condenser.\\nCheck all the wiring connections for the AC system that you can access. There might be a loose connection at the AC compressor, for example. Check along the wires for rubs or cuts.\\nCheck the refrigerant level and top it up. Using a DIY refrigerant kit with a gauge, determine if the system is full or below full. Top up the refrigerant level according to the product's instructions and check the vent temperatures again.\\n\\nRoutine Maintenance Tips\\n\\nRoutine maintenance is essential to ensure your car's air conditioning system continues to blow cool air, especially during warmer months. A simple yet effective maintenance step is routinely checking and replacing the cabin air filter. A dirty or clogged filter can restrict airflow and reduce the system's effectiveness.\\nHaving your air conditioning system professionally inspected at least once a year can help identify potential issues before they lead to significant damage or inefficiency. This inspection should include checking the refrigerant levels and ensuring there are no leaks in the system. Regularly running the AC, even during cooler months, can also prevent seals from drying out and cracking, which can lead to leaks.\\nFurthermore, keeping the car's radiator and condenser clean can prevent overheating and ensure the AC runs efficiently.\\n\\nWhen to Seek Professional Help\\n\\nIf your DIY diagnosis doesn't reveal the problem or you aren't able to conclusively find what's causing the problem, get a professional involved. It's easy to spend a small fortune replacing parts as a guess, and you might still require a visit to the mechanic to get it fixed.\\nWhen you're looking for a repair shop to take your car to, ensure that they have professional-grade equipment to perform AC repairs. Because R134a refrigerant is a controlled material, their technicians need to be certified to recover and recharge your system.\\n\\nPreventative Measures for a Cool Ride\\n\\nTo help avoid AC system problems, keep your engine bay clean, preventing dirt from accumulating on the condenser. As well, make a cabin air filter replacement an annual task right before summer arrives.\\nDuring winter months, use your AC to help defrost the windshield and condition your cabin more effectively. Along with being effective, it can also help you identify if there are issues that need to be addressed before it gets hot outside.\", 'category': 'AC & Climate Control', 'faq_questions': [{'question': 'Why is my car AC blowing hot air?', 'answer': 'There could be a multitude of root causes with common ones being a plugged cabin air filter, bad compressor, clogged expansion valve, or low refrigerant level.'}, {'question': 'Can I fix a hot AC issue myself?', 'answer': \"There are some issues that can be done on your own, while other more involved problems should be addressed by a professional that's certified to handle R134a.\"}, {'question': 'What are the signs of a failing AC compressor?', 'answer': 'Clunking noises when the compressor cycles, intermittent hot and cold air from the vents, and belt squeal are common symptoms of a failing AC compressor.'}, {'question': \"How often should I service my car's AC system?\", 'answer': 'Annually, check that your AC is working properly and change the cabin air filter.'}, {'question': \"When should I consider professional help for my car's AC?\", 'answer': \"If DIY solutions haven't fixed the problem or the repair is more involved than you're ready to tackle, have a professional mechanic work on it for you.\"}]}\n"
     ]
    }
   ],
   "source": [
    "print(articles[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "faq_questions = []\n",
    "for article in articles:\n",
    "    faq_questions.extend(article['faq_questions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "uHlhwY5RUgdV"
   },
   "outputs": [],
   "source": [
    "df_faq = pd.DataFrame(faq_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "v90PQbMdIJIh"
   },
   "outputs": [],
   "source": [
    "has_autozone_text = df_faq['question'].str.contains('AutoZone')\n",
    "df_faq.drop(index=df_faq[has_autozone_text].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Why is my car AC blowing hot air?</td>\n",
       "      <td>There could be a multitude of root causes with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Can I fix a hot AC issue myself?</td>\n",
       "      <td>There are some issues that can be done on your...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What are the signs of a failing AC compressor?</td>\n",
       "      <td>Clunking noises when the compressor cycles, in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How often should I service my car's AC system?</td>\n",
       "      <td>Annually, check that your AC is working proper...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>When should I consider professional help for m...</td>\n",
       "      <td>If DIY solutions haven't fixed the problem or ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0                  Why is my car AC blowing hot air?   \n",
       "1                   Can I fix a hot AC issue myself?   \n",
       "2     What are the signs of a failing AC compressor?   \n",
       "3     How often should I service my car's AC system?   \n",
       "4  When should I consider professional help for m...   \n",
       "\n",
       "                                              answer  \n",
       "0  There could be a multitude of root causes with...  \n",
       "1  There are some issues that can be done on your...  \n",
       "2  Clunking noises when the compressor cycles, in...  \n",
       "3  Annually, check that your AC is working proper...  \n",
       "4  If DIY solutions haven't fixed the problem or ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_faq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1769 entries, 0 to 1782\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   question  1769 non-null   object\n",
      " 1   answer    1769 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 41.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_faq.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning Flan T5 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (3.8.1)\n",
      "Requirement already satisfied: click in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nltk) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nltk) (4.66.2)\n",
      "Requirement already satisfied: datasets in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (2.18.0)\n",
      "Requirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (1.22.4)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (15.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (4.66.2)\n",
      "Requirement already satisfied: xxhash in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets) (2024.2.0)\n",
      "Requirement already satisfied: aiohttp in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (3.9.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (0.21.4)\n",
      "Requirement already satisfied: packaging in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub>=0.19.4->datasets) (4.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas->datasets) (2022.7.1)\n",
      "Requirement already satisfied: six>=1.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: transformers[torch] in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (4.38.2)\n",
      "Requirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers[torch]) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers[torch]) (0.21.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers[torch]) (1.22.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers[torch]) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers[torch]) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers[torch]) (2023.12.25)\n",
      "Requirement already satisfied: requests in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers[torch]) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers[torch]) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers[torch]) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers[torch]) (4.66.2)\n",
      "Requirement already satisfied: torch in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers[torch]) (2.1.2)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers[torch]) (0.28.0)\n",
      "Requirement already satisfied: psutil in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.10.0)\n",
      "Requirement already satisfied: sympy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->transformers[torch]) (1.12)\n",
      "Requirement already satisfied: networkx in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->transformers[torch]) (3.1)\n",
      "Requirement already satisfied: jinja2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->transformers[torch]) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->transformers[torch]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->transformers[torch]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->transformers[torch]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->transformers[torch]) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->transformers[torch]) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->transformers[torch]) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->transformers[torch]) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->transformers[torch]) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->transformers[torch]) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->transformers[torch]) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->transformers[torch]) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->transformers[torch]) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch]) (12.4.99)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->transformers[torch]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->transformers[torch]) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->transformers[torch]) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->transformers[torch]) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sympy->torch->transformers[torch]) (1.3.0)\n",
      "Requirement already satisfied: tokenizers in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (0.15.2)\n",
      "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tokenizers) (0.21.4)\n",
      "Requirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (2024.2.0)\n",
      "Requirement already satisfied: requests in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (4.66.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (4.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (23.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (2024.2.2)\n",
      "Requirement already satisfied: evaluate in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (0.4.1)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from evaluate) (2.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from evaluate) (1.22.4)\n",
      "Requirement already satisfied: dill in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from evaluate) (1.5.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from evaluate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from evaluate) (4.66.2)\n",
      "Requirement already satisfied: xxhash in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from evaluate) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.2.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from evaluate) (0.21.4)\n",
      "Requirement already satisfied: packaging in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from evaluate) (23.2)\n",
      "Requirement already satisfied: responses<0.19 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.13.1)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (15.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
      "Requirement already satisfied: aiohttp in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas->evaluate) (2022.7.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
      "Requirement already satisfied: six>=1.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n",
      "Requirement already satisfied: rouge_score in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (0.1.2)\n",
      "Requirement already satisfied: absl-py in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from rouge_score) (2.1.0)\n",
      "Requirement already satisfied: nltk in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from rouge_score) (3.8.1)\n",
      "Requirement already satisfied: numpy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from rouge_score) (1.22.4)\n",
      "Requirement already satisfied: six>=1.14.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: click in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nltk->rouge_score) (8.1.7)\n",
      "Requirement already satisfied: joblib in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nltk->rouge_score) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nltk->rouge_score) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nltk->rouge_score) (4.66.2)\n",
      "Requirement already satisfied: sentencepiece in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (0.1.99)\n",
      "Requirement already satisfied: huggingface_hub in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (0.21.4)\n",
      "Requirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface_hub) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface_hub) (2024.2.0)\n",
      "Requirement already satisfied: requests in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface_hub) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface_hub) (4.66.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface_hub) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface_hub) (4.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface_hub) (23.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->huggingface_hub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->huggingface_hub) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->huggingface_hub) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->huggingface_hub) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip install nltk\n",
    "pip install datasets\n",
    "pip install transformers[torch]\n",
    "pip install tokenizers\n",
    "pip install evaluate\n",
    "pip install rouge_score\n",
    "pip install sentencepiece\n",
    "pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/utils/generic.py:462: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/utils/generic.py:319: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import T5Tokenizer, DataCollatorForSeq2Seq\n",
    "from transformers import T5ForConditionalGeneration, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from articles import extract_articles\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# Load the tokenizer, model, and data collator\n",
    "MODEL_NAME = \"google/flan-t5-base\"\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(MODEL_NAME)\n",
    "model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME)\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(df_faq)\n",
    "train_test_ds = dataset.train_test_split(test_size=0.2)\n",
    "# We prefix our tasks with \"answer the question\"\n",
    "prefix = \"Please answer this question: \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'answer', '__index_level_0__'],\n",
       "        num_rows: 1415\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'answer', '__index_level_0__'],\n",
       "        num_rows: 354\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "920e0bfc734e4d549f772cd33d65ee9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1415 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bef899104312417eb284b9f1571d2e30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/354 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the preprocessing function\n",
    "\n",
    "def preprocess_function(examples):\n",
    "   \"\"\"Add prefix to the sentences, tokenize the text, and set the labels\"\"\"\n",
    "   # The \"inputs\" are the tokenized answer:\n",
    "   inputs = [prefix + doc for doc in examples[\"question\"]]\n",
    "   model_inputs = tokenizer(inputs, max_length=128, truncation=True)\n",
    "  \n",
    "   # The \"labels\" are the tokenized outputs:\n",
    "   labels = tokenizer(text_target=examples[\"answer\"], \n",
    "                      max_length=512,         \n",
    "                      truncation=True)\n",
    "\n",
    "   model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "   return model_inputs\n",
    "\n",
    "# Map the preprocessing function across our dataset\n",
    "tokenized_dataset = train_test_ds.map(preprocess_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'answer', '__index_level_0__', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1415\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'answer', '__index_level_0__', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 354\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /teamspace/studios/this_studio/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"punkt\")\n",
    "metric = evaluate.load(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "   preds, labels = eval_preds\n",
    "\n",
    "   # decode preds and labels\n",
    "   labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "   decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "   decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "   # rougeLSum expects newline after each sentence\n",
    "   decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "   decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "\n",
    "   result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "  \n",
    "   return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Parameters\n",
    "L_RATE = 3e-4\n",
    "BATCH_SIZE = 8\n",
    "PER_DEVICE_EVAL_BATCH = 4\n",
    "WEIGHT_DECAY = 0.01\n",
    "SAVE_TOTAL_LIM = 3\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "# Set up training arguments\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "   output_dir=\"./results\",\n",
    "   evaluation_strategy=\"epoch\",\n",
    "   learning_rate=L_RATE,\n",
    "   per_device_train_batch_size=BATCH_SIZE,\n",
    "   per_device_eval_batch_size=PER_DEVICE_EVAL_BATCH,\n",
    "   weight_decay=WEIGHT_DECAY,\n",
    "   save_total_limit=SAVE_TOTAL_LIM,\n",
    "   num_train_epochs=NUM_EPOCHS,\n",
    "   predict_with_generate=True,\n",
    "   push_to_hub=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "   model=model,\n",
    "   args=training_args,\n",
    "   train_dataset=tokenized_dataset[\"train\"],\n",
    "   eval_dataset=tokenized_dataset[\"test\"],\n",
    "   tokenizer=tokenizer,\n",
    "   data_collator=data_collator,\n",
    "   compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1770' max='1770' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1770/1770 09:52, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.149851</td>\n",
       "      <td>0.325831</td>\n",
       "      <td>0.135755</td>\n",
       "      <td>0.264907</td>\n",
       "      <td>0.270366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.093176</td>\n",
       "      <td>0.325019</td>\n",
       "      <td>0.133975</td>\n",
       "      <td>0.263560</td>\n",
       "      <td>0.270240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.070600</td>\n",
       "      <td>2.108422</td>\n",
       "      <td>0.320579</td>\n",
       "      <td>0.137358</td>\n",
       "      <td>0.262536</td>\n",
       "      <td>0.268787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.070600</td>\n",
       "      <td>2.157729</td>\n",
       "      <td>0.329891</td>\n",
       "      <td>0.145051</td>\n",
       "      <td>0.272676</td>\n",
       "      <td>0.278419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.070600</td>\n",
       "      <td>2.221337</td>\n",
       "      <td>0.324979</td>\n",
       "      <td>0.140882</td>\n",
       "      <td>0.266297</td>\n",
       "      <td>0.271246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.278700</td>\n",
       "      <td>2.276956</td>\n",
       "      <td>0.324359</td>\n",
       "      <td>0.140910</td>\n",
       "      <td>0.266741</td>\n",
       "      <td>0.271738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.278700</td>\n",
       "      <td>2.402885</td>\n",
       "      <td>0.326588</td>\n",
       "      <td>0.143634</td>\n",
       "      <td>0.269227</td>\n",
       "      <td>0.275727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.278700</td>\n",
       "      <td>2.450764</td>\n",
       "      <td>0.327633</td>\n",
       "      <td>0.144797</td>\n",
       "      <td>0.267569</td>\n",
       "      <td>0.274056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.897400</td>\n",
       "      <td>2.572177</td>\n",
       "      <td>0.322558</td>\n",
       "      <td>0.139045</td>\n",
       "      <td>0.264247</td>\n",
       "      <td>0.270081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.897400</td>\n",
       "      <td>2.615739</td>\n",
       "      <td>0.328173</td>\n",
       "      <td>0.144781</td>\n",
       "      <td>0.268941</td>\n",
       "      <td>0.274802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/generation/utils.py:1178: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/generation/utils.py:1178: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/generation/utils.py:1178: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/generation/utils.py:1178: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1770, training_loss=1.314621032025181, metrics={'train_runtime': 592.9578, 'train_samples_per_second': 23.863, 'train_steps_per_second': 2.985, 'total_flos': 443392422460416.0, 'train_loss': 1.314621032025181, 'epoch': 10.0})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "last_checkpoint = \"./results/checkpoint-1500\"\n",
    "\n",
    "finetuned_model = T5ForConditionalGeneration.from_pretrained(last_checkpoint)\n",
    "tokenizer = T5Tokenizer.from_pretrained(last_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/generation/utils.py:1178: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad>Synthetic blend is more expensive than conventional oil, and it's less durable than conventional oil\n"
     ]
    }
   ],
   "source": [
    "my_question = \"What are the disadvantages of synthetic blend oil?\"\n",
    "inputs = \"Please answer to this question: \" + my_question\n",
    "\n",
    "inputs = tokenizer(inputs, return_tensors=\"pt\")\n",
    "outputs = finetuned_model.generate(**inputs)\n",
    "answer = tokenizer.decode(outputs[0])\n",
    "from textwrap import fill\n",
    "\n",
    "print(fill(answer, width=80))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping \"O Mecânico\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from seaborn) (1.22.4)\n",
      "Requirement already satisfied: pandas>=1.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from seaborn) (1.5.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from seaborn) (3.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.49.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2022.7.1)\n",
      "Requirement already satisfied: six>=1.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mecanico import extract_posts\n",
    "import pandas as pdimport\n",
    "from nltk import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = extract_posts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for post in posts:\n",
    "    sentences.extend(post['sentences'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['15) Com um pano, remova o excesso de graxa.',\n",
       " '16) Localize a trava externa da junta homocinética.',\n",
       " '17) Com o auxílio de um alicate, solte a trava da junta homocinética.',\n",
       " '18) Retire a junta homocinética e a coifa antiga.',\n",
       " '19) Limpe o semieixo e faça uma verificação do estado das estrias e do canal da trava da homocinética.',\n",
       " '20) Neste Chevrolet Celta 2011 foi utilizado o kit VKJA 41000 A, da SKF, que já inclui a homocinética fixa com porca, coifa, abraçadeiras, graxa de bissulfeto de molibdênio e manual de montagem. Utilize todos os novos componentes do kit.',\n",
       " '21) Antes de iniciar a montagem da nova homocinética, proteja a extremidade do semieixo com uma fita a fim de evitar rasgos causados pelas estrias no momento da instalação da coifa.',\n",
       " '22) Instale a nova coifa no semieixo e retira a fita utilizada para proteção.',\n",
       " '23) Faça a lubrificação da junta homocinética com a graxa de bissulfeto de molibdênio.',\n",
       " '24) Introduza a junta homocinética no semieixo, observando e certificando-se do correto travamento.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[20:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7fce07582da0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "sentences_lengths = []\n",
    "\n",
    "for sentence in sentences:\n",
    "    tokens = tokenize.word_tokenize(sentence)\n",
    "    sentences_lengths.append(len(tokens))\n",
    "\n",
    "sentences_lengths = np.array(sentences_lengths)\n",
    "\n",
    "sns.displot(sentences_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0014411529223378704"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences_lengths[sentences_lengths > 1024])/len(sentences_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55.60432345876701"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(sentences_lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning GPT-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://colab.research.google.com/drive/13dZVYEOMhXhkXWfvSMVM1TTtUDrT6Aeh?usp=sharing#scrollTo=63t_69HjlwAj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://tuanatran.medium.com/fine-tuning-large-language-model-with-hugging-face-pytorch-adce80dce2ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, RandomSampler, SequentialSampler\n",
    "torch.manual_seed(42)\n",
    "\n",
    "from transformers import GPT2LMHeadModel,  GPT2Tokenizer, GPT2Config, GPT2LMHeadModel\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('pierreguillou/gpt2-small-portuguese', bos_token='<|startoftext|>', eos_token='<|endoftext|>', pad_token='<|pad|>')\n",
    "tokenizer.model_max_length=1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The max model length is 1024 for this model, although the actual embedding size for GPT PT-BR small is 1024\n",
      "The beginning of sequence token <|startoftext|> token has the id 50257\n",
      "The end of sequence token <|endoftext|> has the id 0\n",
      "The padding token <|pad|> has the id 50258\n"
     ]
    }
   ],
   "source": [
    "print(\"The max model length is {} for this model, although the actual embedding size for GPT PT-BR small is 1024\".format(tokenizer.model_max_length))\n",
    "print(\"The beginning of sequence token {} token has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.bos_token_id), tokenizer.bos_token_id))\n",
    "print(\"The end of sequence token {} has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.eos_token_id), tokenizer.eos_token_id))\n",
    "print(\"The padding token {} has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.pad_token_id), tokenizer.pad_token_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT2Dataset(Dataset):\n",
    "\n",
    "  def __init__(self, txt_list, tokenizer, gpt2_type=\"gpt2\", max_length=1024):\n",
    "\n",
    "    self.tokenizer = tokenizer\n",
    "    self.input_ids = []\n",
    "    self.attn_masks = []\n",
    "\n",
    "    for txt in txt_list:\n",
    "\n",
    "      encodings_dict = tokenizer('<|startoftext|>'+ txt + '<|endoftext|>', truncation=True, max_length=max_length, padding=\"max_length\")\n",
    "\n",
    "      self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n",
    "      self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n",
    "    \n",
    "  def __len__(self):\n",
    "    return len(self.input_ids)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    return self.input_ids[idx], self.attn_masks[idx] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16,861 training samples\n",
      "1,874 validation samples\n"
     ]
    }
   ],
   "source": [
    "dataset = GPT2Dataset(sentences, tokenizer, max_length=1024)\n",
    "\n",
    "# Split into training and validation sets\n",
    "train_size = int(0.9 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "print('{:>5,} training samples'.format(train_size))\n",
    "print('{:>5,} validation samples'.format(val_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "# Create the DataLoaders for our training and validation datasets.\n",
    "# We'll take training samples in random order. \n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  # The training samples.\n",
    "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
    "            batch_size = batch_size # Trains with this batch size.\n",
    "        )\n",
    "\n",
    "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the model\n",
    "model = GPT2LMHeadModel.from_pretrained(\"pierreguillou/gpt2-small-portuguese\")\n",
    "\n",
    "# this step is necessary because I've added some tokens (bos_token, etc) to the embeddings\n",
    "# otherwise the tokenizer and model tensors won't match up\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "device = torch.device(\"cuda\")\n",
    "model.cuda()\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some parameters I cooked up that work reasonably well\n",
    "\n",
    "epochs = 5\n",
    "learning_rate = 5e-4\n",
    "warmup_steps = 1e2\n",
    "epsilon = 1e-8\n",
    "\n",
    "# this produces sample output every 100 steps\n",
    "sample_every = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
    "optimizer = AdamW(model.parameters(), lr = learning_rate, eps = epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of training steps is [number of batches] x [number of epochs]. \n",
    "# (Note that this is not the same as the number of training samples).\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "# This changes the learning rate as the training loop progresses\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = warmup_steps, \n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time(elapsed):\n",
    "    return str(datetime.timedelta(seconds=int(round((elapsed)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 5 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   100  of  8,431. Loss: 0.15877652168273926.   Elapsed: 0:00:23.\n",
      "0: Grupo. do disco os destaques são os componentes elétricos e o sistema de limpeza, que pode ser indicado com o equipamento mecânico instalado. O disco é polidos no padrão de 2400 L (13.7V). Além de não ter problema com o desgaste do disco pode ser utilizado a troca de combustível, pois é recomendado ao uso de motor diesel. Além disso as especificações para o disco são idênticas àquelas para o sistema eletrônico e com os componentes elétricos o disco é com uma potência máxima de 150 cv (59 cv de potência, 5.2 V) com potência de 100 cv (16 cv, 5.8 V), com câmbio automático manual, de 3 marchas e câmbio manual, com comando manual (15-T) (5 marchas), câmbio automático e freios ABS. O disco é feito em linha de montagem do, com injeção eletrônica, de combustível líquido de 5 litros (2 T), de 0.5 T de Nitro de Na (7.0 N),\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   200  of  8,431. Loss: 0.15369173884391785.   Elapsed: 0:00:49.\n",
      "0: tário e a sua localização na estrada. Após ter sido retirada na sua volta, passou o teste do veículo (16/12/2018) de apoio que ficou sem problema. (ADMU) é o sistema de freio automático do veículo que determina a posição do cilindro. É utilizado para o aumento do câmbio dianteiro e de troca. O sistema está indicado por uma chave de ignição e é utilizado na carcaça, quando as válvulas estão em funcionamento. O modelo 1D de 70 mm (18 mm atrás do cilindro) está indicado. Esse sistema está indicado no veículo (18 mm atrás do cilindro). O motor do carro possui as marchas em marcha constante (12v) e câmbio automático, a indicação é 12 CV. Quando o combustível está em aplique, a válvula também é acionado, quando possui a chave de ignição. Essa chave também é utilizada nas trocas e na transmissão (18 mm atrás do cilindro) na transmissão (18 mm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   300  of  8,431. Loss: 0.2308550328016281.   Elapsed: 0:01:14.\n",
      "0: nos do sistema, com o qual a chave do módulo de comando é o mesmo da chave da cabine. é um sistema elétrico, desenvolvido pela unidade de transporte de ônibus de todo o Brasil para ônibus de carga em ônibus urbano. Com o auxílio do veículo de alta performance ônibus, a diferença na utilização de combustível e nas condições de uso entre os veículos é de 40% (54) a 40% (30) do custo do veículo de carga. O sistema é dotado de três baterias, a saber: um por cilindro, um por cilindro e um por cilindro de dupla plaqueta.\n",
      "O sistema vem sendo utilizado desde meados do século XX pelos ônibus que realizam a manutenção de ônibus, tanto para ônibus de carga quanto para ônibus urbano. O ônibus do tipo ônibus urbano também vem sendo usados na manutenção de outros veículos, como ônibus de ônibus diesel, ônibus urbano e ônibus de ônibus ABS. O sistema foi desenvolvido na própria linha da ônibus ônibus da Fiat entre 2003 e 2005,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   400  of  8,431. Loss: 0.39087721705436707.   Elapsed: 0:01:39.\n",
      "0:  along, é uma cidade da região do vale do Rio das Bocas, localizada entre a cidade de São Bernardo de Campo a São Bernardo do Campo, e São Bernardo do Campo-SP. Também conhecida como Porto Alegre ou Porto Alegre, é uma cidade com um pouco mais de 30 anos de história, sendo que já estão entre os mais importantes pólos do estado e também um dos mais importantes centros de serviços de qualidade do Brasil. Entre as muitas funções de direção do sistema de arrefecimento e da bomba d’água, Porto Alegre possui a responsabilidade das respectivas unidades elétricas e de sistema de transmissão de óleo, com um papel cada vez mais importantes. Vale ressaltar que o sistema de troca de óleo é a base do sistema de troca de óleo-pirólise aplicado no sistema hidráulico do motor. é um modelo do tipo Peugeot Eaton, utilizado na marca da Honda. Ele foi o primeiro veículo da Honda a ter um câmbio interno no mercado na versão\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   500  of  8,431. Loss: 0.45087066292762756.   Elapsed: 0:02:04.\n",
      "0: •: Soldas/2-3\n",
      "Drive 8000 vezes no máximo. A Naisulis do – Sone, A reportagem da reportagem tem como ponto de referência os pontos de referência para este processo na produção de um líquido refrigerante. (OUT) – Com 13 anos de história e 12 prêmios, esta cidade do México possui a quinta posição da IUMOM e ainda em primeiro. Na comparação, o Brasil ocupa primeiro lugar, atrás de São Paulo (11º lugar entre os principais). A cidade tem uma economia, é bem formada com vários tipos de serviços: o sistema de energia, o papel de serviços não-utilizados no\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   600  of  8,431. Loss: 0.11235810071229935.   Elapsed: 0:02:29.\n",
      "0:  blocoO mecânico não é o único a prestar serviço aos clientes do carro. Antes da instalação do sensor de ABS, os veículos da cidade de São Paulo já tinham problemas com sua vida útil. O filtro não possui filtros para a corrente de baixa pressão, que é responsável pela perda de vida de combustível. São os filtros que o veículo utiliza. Antes de instalação, é preciso tomar cuidado com o fluxo de ar do filtro e verificar que a sua aplicação é normal, o que permite que ele não seja interrompida. “O filtro tem o objetivo de não agredir o motor e provocar acidentes”, alerta o gerente Comercial da Bosch Automotive Co. O filtro é responsável pelo abastecimento do fluido de poluentes do ar e também, é responsável por o balanço de potência de baixa pressão da bomba de ar. mangueiras do\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   700  of  8,431. Loss: 0.4397437274456024.   Elapsed: 0:02:54.\n",
      "0: 89 de entrada do sistema. Neste caso a pressão ocorre na entrada, enquanto os resíduos do sistema são filtradores. é um serviço de alta tecnologia da Shell que recebe, em média, 1,030 MW, capaz de entregar a emissão de alta potência do motor, com potência de 240 cv, ou 4 kgfm ou 5,0 kgfm de torque máximo máximo máximo que seja a potência obtida por motor. Por fim, o programa possui fácil substituição de componentes, já que o motor está sujeito à sua revisão sem a correção por meio da recomendação de diagnóstico do profissional. “O veículo é dividido em uma unidade de injeção de combustível e um motor-leve e tem em sua bancada a caixa de transferência da bomba de alta pressão”, comenta Alexandre Vilmar de A. KYBB.  Ele também alerta sobre a possibilidade de não-conversação no comando do motor quando a correia hidráulica de freio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   800  of  8,431. Loss: 0.23727595806121826.   Elapsed: 0:03:19.\n",
      "0: isc: “o mecânico não pode retirar o conjunto, mas o carro sempre está funcionando, sempre no elevador de alta velocidade e é legal que a tubulação esteja no seu acesso. “É bom lembrar que o carro está em uso no momento do funcionamento normal, ou seja, uma vez que o motor está parado e a potência e a potência estão totalmente na mesma. Mas se você remover a tubulação, o motor pode não funcionar até a bomba d’água, se você não reinstalar o conjunto e o carro será parada. O carro estava totalmente parado, só há a possibilidade de ele parar ou pegar numa bateria. Se ele ficar parado e o carro vai parar em seguida a bomba d’água vai dar continuidade, já que o motor está totalmente funcionando. Ele sempre está, mas o carro já estava parado”. Se a bomba d’água não for removido, pode causar perda de potência.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   900  of  8,431. Loss: 0.41053807735443115.   Elapsed: 0:03:44.\n",
      "0:  negociadoCom os amortecedores nas ruas, foram incorporadas os conjuntos de amortecedores convencionais. A manutenção em estradas de estradas fechadas é uma grande importância, já que em caso de uso severo, pode danificar o cabeçote da torre de suspensão, possibilitando ao amortecedor a perder sua posição. Para não forçar a torre de suspensão, basta fazer uma inspeção.  Traque o tensionador de freio, que é instalado em um volante para atestar se é necessário remover o tensionador do freio.   É importante lembrar que a peça deve ter sido aplicada em todas as suas etapas, não só no centro, mas em todas as faces do veículo. (A.M.C) é um mecânico mecânico de componentes do Brasil e proprietário de uma oficina de montagem que fabrica cerca de 30 produtos no mercado internacional, dos quais cerca de 1,8 mil são fabricados pela Bosch. A montagem segue a linha da Ford (R7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1,000  of  8,431. Loss: 0.10827979445457458.   Elapsed: 0:04:09.\n",
      "0:  práticaA montagem segue os mesmos padrão da suspensão dianteira, por isso, as peças são de fácil reparabilidade. O tensionador é acionado por uma chave combinada 17 mm (1,5 mm do primeiro cilindro) e o coletor de admissão já vem alinhado. A correia está de um comprimento de 15 mm com uma função de regulagem da bomba de escape para atender o torque de aperto, que é de 6,2 Nm (1,5 a 5,4 mm de torque). (SKD) é um serviço de informações e informações a base de informações relacionados ao veículo e à linha de veículos, através do fabricante e pela fabricante de produtos, na América do Sul. Seu proprietário fica localizado no Valeo, em Valinhos- RJ. O catálogo de produtos do serviço é baseado nos mapas de manutenção do Peugeot 206 e Citroën C3 S10. (28 de junho de 2007) é um técnico de\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1,100  of  8,431. Loss: 0.2522244155406952.   Elapsed: 0:04:34.\n",
      "0:  QuirImotivo de ar, ou ar condicionado, também conhecido como ar do motor, está localizado no cabeçote superior dos pneus, no compartimento do reservatório, no compartimento de apoio para o motor, com caixa de câmbio, sistema ABS, e motor embreagem. Sua função é garantir a estabilidade e o funcionamento de todo o conjunto, independentemente de um veículo ou veículo em estrada urbano. O funcionamento do sistema é feito a cada 20 mil quilômetros. da Revista O Mecânico teve um acidente no trânsito rodoviário nacional em pleno trânsito e foi possível observar um pequeno incidente com trânsito urbano em todo o país e, consequentemente, com o veículo. Porém, o acidente nem sempre foi um problema crônicos que nem sempre foi aparente. Porém, os problemas de trânsito podem existir na parte traseira do veículo, no lado esquerdo do veículo (no lado direito da traseira do acelerador), em outros carros e em ruas, como a picape. E não se esqueça de utilizar o acelerador para\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1,200  of  8,431. Loss: 0.43338391184806824.   Elapsed: 0:04:59.\n",
      "0:  Foster8) Inicie a torre de suspensão do motor para ter acesso ao bloco: a montagem do bloco deve ser feita por diversos fatores. Por isso, o principal que deve ser feito é um sistema mais simples com mais facilidade para manutenção e com maior durabilidade. Se o bloco for removido dentro da instalação de manutenção, o motor precisará de ferramentas especiais para a desmontagem e manutenção correto. Na mesma hora, utilize uma chave Allen de emergência., que é o coordenador de treinamento do programa de treinamento do Instituto Ford, em Valinhos, SP, levou o evento para a imprensa, onde o proprietário do sistema de sincronismo da empresa levou a seguinte observação: “É imperativo ter acesso aos componentes que podem facilitar o desempenho de um carro no trânsito urbano”, afirma. (5 de junho de 2013) é uma das sondas mais antigas que já foram aprovadas por uma grande imprensa do setor com foco em auxiliar a manter a tecnologia em dia. E, de\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1,300  of  8,431. Loss: 0.06648953258991241.   Elapsed: 0:05:24.\n",
      "0:  Santíssimo.   Brasil Brasil | Brasil | Al Brasil | Brasil | Al Brasil | Al Brasil | Al Brasil | Al Brasil | Al Brasil | Al Brasil | Al Brasil | Al Brasil | Al Brasil | Al Brasil | Al Brasil | Al Brasil | Al Brasil | Al Brasil | Al Brasil | Al Brasil | Al Brasil | Al Brasil | Al Brasil | Al Brasil | Al Brasil | Al Brasil | Al Brasil | Al Brasil | Al Brasil | Al Brasil | Al Brasil | Al Brasil | Al Brasil | Al Brasil | Al Brasil | Al Brasil | E, T, E,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1,400  of  8,431. Loss: 0.20496244728565216.   Elapsed: 0:05:49.\n",
      "0:  repleAcompanhe agora os modelos: Volkswagen Spin Pack, Volkswagen TRO, Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1,500  of  8,431. Loss: 0.3214110732078552.   Elapsed: 0:06:14.\n",
      "0:  aband7- Remova o sincronizador e retire o óleo, que é fixado com trava. O óleo foi fabricado com fábrica italiana, o motor E.torQ2001-B, que segue a mesmas regra de manutenção do motor E.torQ2001-B (3). Aspecto: 8606907 O Mecânico O Mecânico  Communal   Aspecto: 86069077, Aspecto: 8606907, 2017, teve o desempenho melhor do modelo desde a estreia dos motores do Gol, com 2.200cv a menos em relação a outros motores da Ford. Por baixo, as versões de 8606907 de fábrica são quatro cilindros.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1,600  of  8,431. Loss: 0.04926364868879318.   Elapsed: 0:06:39.\n",
      "0:  Borgonha– Solte os parafusos de fixação da correia dentada e a junta de fixação da junta de fixação da junta com um martelo., conhecido popularmente como “Zóleo do virabrequim”, está localizado na região do coletor de escapamento. Faz a saída da turbina e os terminais da conexão com o filtro de ar de admissão. Por cima, a bateria fica localizada., conhecido popularmente como “Zóleo do virabrequim”, está localizado na região do coletor de escapamento. Por cima, a bateria fica localizada., conhecido popularmente como “Zóleo do virabrequim” é um item muito popular entre o mecânico e o mecânico profissional. O item é um utilitário de série, mas sem perder o ponto., conhecido popularmente como “Zóleo do virabrequim”, está localizado em um local\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1,700  of  8,431. Loss: 0.39272335171699524.   Elapsed: 0:07:04.\n",
      "0:  ModNa montagem, não se esquecer de engatar uma sonda lambda de alta pressão para que a sonda lambda possa ser trocada, com o auxílio de um martelo para soltá-la. Lembre-se que o torque final da peça é de 55.750 rpm e o torque final da sonda lambda estará em torno de 50.000 rpm. Neste caso, observe o torque final do parafuso de cabeça para baixo: de 50.000 rpm e em torno de 60.000 rpm. Depois, utilize uma chave L12 mm para soltar a sonda. Na montagem, o torque final da sonda lambda é de 27.000 rpm e a mesma foi trocada com o auxílio de um martelo. com injeção por ar (COMO: 4.5) com capacidade para receber 6.000 (COMO: 35)itro de potência, com fácil acesso à fixação do suporte de sustentação. A injeção é automática de três estágios\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1,800  of  8,431. Loss: 0.19349679350852966.   Elapsed: 0:07:29.\n",
      "0: cos6. A primeira etapa de montagem da peça é na seqüência: Todo este conjunto é construído por profissionais da Michelin em parceria com a General Motors, e sua oficina é ligada ao mecânico, responsável por manter o nível de óleo e temperatura do fluido de freio da sua oficina. “Quando o motor estiver no chão com a roda suspensa, o turbo é o responsável pela manutenção do sistema hidráulico e, se estiver suspenso e não estiver mais, o turbo é o responsável pelo diagnóstico dos componentes do sistema de alta pressão. O turbo tem que ser acionado por parte dacionar­ção do motor com o pedal parado e o turbo, que é o último componente, não é capaz de manter a eficiência do seu movimento, fazendo com que o carro se coloque o óleo. O mecânico pode escolher um outro, dependendo da condição de uso”, alerta.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1,900  of  8,431. Loss: 0.27877697348594666.   Elapsed: 0:07:54.\n",
      "0: êm13) Remova os parafusos de fixação da correia elástica que fixam a correia por fixado no cavalete, utilizando a chave L 13 mm (13a). Remova o tensionador de fixação do virabrequim, que é para cima (13b). Depois, remova a correia elástica do lado direito e aperte o parafuso de fixação do parafuso. (22) (45) Com o auxílio de Gustavo Lalli, o painel de confirmação dos modelos com as sondas lambdas do INS, assim como o procedimento completo de substituição dos componentes do veículo, é considerado o momento certo da substituição. (19) e o painel de fotos de Marcelo Caretta a ser seguido foram apresentados nas apresentação do painel. Depois de analisar a estrutura dos veículos, Roberto Santos, diretor de Novos Negócios da ZF, e André Haddad, consultor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 2,000  of  8,431. Loss: 0.20327818393707275.   Elapsed: 0:08:19.\n",
      "0: anças6. Com o conjunto do conjunto, aplique uma medida na sequência e faça o ajuste correto pelo circuito de alimentação da correia. O circuito vai para o coletor, próximo à polia, gerando uma medida na medição da tensão do coletor, evitando que ele fique cheio ou com nenhuma tensão. A tensão do coletor deve ser fixada em um valor maior que a unidade de carga, com que a tensão seja reduzida. A tensão de aperto, por causa de sua natureza diferente, vai causar baixa resistência, baixa carga, baixo desempenho ou consumo de energia. Evite que um veículo caia. Mais informações:  Mais informações:  Mais informações:   Mais informações:  Mais informações:  Mais informações:  Mais informações:  Mais informações: Mais informações:   Mais informações:   Mais informações:  Mais informações:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 2,100  of  8,431. Loss: 0.34851017594337463.   Elapsed: 0:08:44.\n",
      "0: illeA substituição do tensor de força é feita de forma progressiva, se houver, seguindo a indicações da fabricante e os componentes de suspensão para que se reinstale no veículo. Como esse tipo de processo de redução das pressões no sistema, há algum momento, quando um determinado pneu sofre muita rotação irregular, o técnico do SENAI-Vila Leopoldina, Edivaldo Codílio, é recomendado. O Civic Civic Civic GNV é um Civic Civic com motor 1.5 2.0 lp de potência com 8,2 rpm, de 4,7 rpm, em duas versões: a versão 1.6 – tração 4 velocidades, e a versão 2.5 – 4 velocidades – com motor 2.0 1.6 lp de potência, com 8,3 km rodados – não deve!               \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 2,200  of  8,431. Loss: 0.2972087264060974.   Elapsed: 0:09:09.\n",
      "0:  encontrava11) Com o amortecedor ainda instalado, retire o conjunto e passeá até o cavalete. Remova agora o conjunto. Depois de apertar o coxim com chave, solte a porca de fixação do amortecedor e aplique o torque máximo de 10 Nm. O O A barra estabilizadora do motor 2.0 de potência com óleo lubrificante de 5W20. A primeira troca de óleo do motor a ser feita com aditivos de má qualidade e com viscosidade superior a 50 Nm é realizada por Matheus, diretor de Assistência Técnica da Valeo. Emanoel Nakata, localizada na parte externa do  Acompanhe a situação do espaço de arrefecimento\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 2,300  of  8,431. Loss: 0.14090704917907715.   Elapsed: 0:09:34.\n",
      "0: cis3) Após remover a nova tampa de válvulas, remova a porca da flange da flange. Substitua a porca com a braçadeira. (11) (11) (11) (11)    Na figura 4, é possível ver que há alguns rasgos gastos no alojamento do filtro de óleo que são vendidos como um todo. Não se trata apenas de um cárter, mas também uma válvula termostática. “É feita por duas velas de calor, e o combustível está dentro da válvula termostática. Se for reutilizada por uma peça ou por uma válvula termostática, não é necessário desmontar os cabos. Por isso, é comum a ser trocada. Se necessário, é possível ser reinstalada no filtro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 2,400  of  8,431. Loss: 0.2483583688735962.   Elapsed: 0:09:59.\n",
      "0:  colisãoCausa provável: Entrega em que não existe, quando o conjunto de freios é danificado. (11) Atenção: É possível a troca de dois parafusos do eixo traseiro para a fixação (11). (11) O Mecânico (11) É um mecânico mecânico de automóveis que trabalha para a Revista O Mecânico e ao revistas O Mecânico e O Mecânico. O mecânico é responsável pela manutenção do câmbio dianteiro da Toyota Corolla, ano 2007, o câmbio CVT é o de uso severo, com uma faixa de substituição rápida, é o que tem a função de diminuir a consumo de combustível. É possível acessar os pneus em caminhões com rodas com menos atrito e, consequentemente, menos espaço. (11) O Denox é um componente eletrônico que possui função de movimentar a capa protetora ou proteção protetora do amortecedor (11). “O componente precisa do\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 2,500  of  8,431. Loss: 0.25178205966949463.   Elapsed: 0:10:24.\n",
      "0: ásEm relação à utilização de tecnologias remanufaturadas, a Bosch explica que não há normas para adaptar a versão em veículos comerciais no mercado de motores e não existem normas para adaptar a bomba hidráulica com motores mais modernos. “É muito comum fazer a conversão entre a bomba hidráulica de 3 cilindros, o que não é possível para se fazer no sistema da válvula de retenção do ar-condicionado”. O (2023)  O procedimento de troca preventiva e completo das válvulas é a principal parte da manutenção do sistema do motor 1.0, que tem duas válvulas (1.0 E.torQ1.0), três marchas, duas transmissão e 2.0 e dois em dupla com a mesma válvula. O manual do proprietário afirma o procedimento foi feito com sucesso. (2023) é o nome\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 2,600  of  8,431. Loss: 0.1293887346982956.   Elapsed: 0:10:49.\n",
      "0:  Sorocaba4) Veja o estado do sensor de rotação, que fica próximo a o eletro-guia do sensor, onde está representado, e onde é armazenado o material utilizado na placa de leitura. Utilize uma chave de fenda que é acionada por dois parafusos, um e a outra. O Mecânico Solução da troca Motorista (2013) Motorista é um dos principais marcas comerciais do Brasil. Suas sedes estão na capital e o seu objetivo é fazer todo o possível para fazer o seu cliente, seja proprietário, proprietário da montadora, proprietário do caminhão e proprietário da oficina. Apesar de ser um empresa, o mecânico e proprietário de veículos comerciais, foi proprietário e proprietário do Grupo América Latina, que comercializa o álcool e a mistura para atender as\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 2,700  of  8,431. Loss: 0.05410550534725189.   Elapsed: 0:11:14.\n",
      "0: rianA suspensão dianteira é McPherson, mas o câmbio é hidráulico. A direção é manual (1ª geração), fazendo com que a parte dianteira seja automática. As laterais devem estar completamente assentadas na roda. A suspensão dianteira é mecânica (com amortecedores de 6” para cima ou 3ª geração), e a direção é feita por cabos no conjunto (1ª geração).O (11) (11) •• Não esqueça de utilizar o líquido de arrefecimento no intervalo especificado pelo fabricante – a KUO (KWA) é recomendada pela FPTF (Associação Nacional das Fabricantes de Serviços Automotivos) e não pelo ASEI (Associação Nacional da Fabricantes de Serviços Automotivos).   Obs: Em\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 2,800  of  8,431. Loss: 0.2752264440059662.   Elapsed: 0:11:39.\n",
      "0:  Wor8) A peça possui uma extensão de aproximadamente 2.100 vezes, portanto é possível colocar uma peça com um diâmetro maior do que a necessária, de 5.496mm. (11) foi o escolhido pela bateria, que faz parte do componente, mas é mais leve. Agora, há mais espaço (8). (12) foi o escolhido pela bateria, que faz parte do componente, mas não é mais leve. Agora, há mais espaço (8). (13) é o próximo carro do veículo Fiat Cronos CVT e tem fácil substituição. Afinal, o modelo tinha que correr, mas o mecânico tinha que aprender. (14) é um dos componentes automotivos mais importantes da oficina de ônibus. É o sistema de distribuição mais complexo das linhas Peugeot e Saveiro (15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 2,900  of  8,431. Loss: 0.1522243618965149.   Elapsed: 0:12:04.\n",
      "0:  desporAo conectar os cabos de partida de ar no volante, o equipamento deve estar em posição segura, próximo ao quadro do motor de partida, próximo ao coletor de escapamento. Para isso, solte os parafusos da fixação inferior da bobina auxiliar. Os parafusos que fixam os conectores com a proteção, o guarda-pó, a bandeja, os anéis, as polias, os bielas, os roletas, o rolamento, as arruelas e o rolamento estão sem travamento.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 3,000  of  8,431. Loss: 0.34806424379348755.   Elapsed: 0:12:29.\n",
      "0:  Fen2) Remova a correia sincronizadora com o comando de válvulas. Remova o coletor de combustível. é uma plataforma do tipo dupla-eixo, que utiliza como referência o sistema de ignição (7), mas que utiliza uma vela de ignição diferente, com uma ponta ou outra de vela. No seu interior, a correia é conectada eletricamente eletricamente e só tem um cabo. A pressão gerada por ela é controlada por um equipamento eletrônico; ela se encontra pelo módulo eletrônico de cada motor. Numeração de válvulas (conhecido como “o’ring”) é uma plataforma da correia sincronizadora que utiliza um chicote de ignição com uma agulha e uma ponta da agulha, sendo responsável pelas emissões de combustível. No seu interior,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 3,100  of  8,431. Loss: 0.043352361768484116.   Elapsed: 0:12:54.\n",
      "0: cabeO primeiro passo para remover essa correia sincronizadora da transmissão manual é remover o garfo superior. Oco da Mahle Solução: Soltar o motor Nneoscópio \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 3,200  of  8,431. Loss: 0.25971174240112305.   Elapsed: 0:13:19.\n",
      "0:  (...)4) Antes de remover a válvula de admissão, é possível tirar dois parafusos fixados por parafusos na caixa seca: uma por cima e outra por baixo. Não, deixe o eixo do volante sempre dentro do cilindro-mestre. é um carro da marca francesas Peugeot Citroën na categoria “heater” e que equipa o Renegade, em especificação do Citroën C3. O nome vem do sistema de injeção de combustível que equipa o modelo Peugeot 208, que equipa o hatch hatch. O projeto é, mas, sim, utilizado por uma versão, o tipo “heater” do motor (4A). é um dos veículos com motor 1.4 GSR4 com turbocompressor turbocompressor de 105 cv. é equipado com sistema de alimentação direta direta (4b), com\n"
     ]
    }
   ],
   "source": [
    "total_t0 = time.time()\n",
    "\n",
    "training_stats = []\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "for epoch_i in range(0, epochs):\n",
    "\n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    total_train_loss = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_labels = batch[0].to(device)\n",
    "        b_masks = batch[1].to(device)\n",
    "\n",
    "        model.zero_grad()        \n",
    "\n",
    "        outputs = model(  b_input_ids,\n",
    "                          labels=b_labels, \n",
    "                          attention_mask = b_masks,\n",
    "                          token_type_ids=None\n",
    "                        )\n",
    "\n",
    "        loss = outputs[0]  \n",
    "\n",
    "        batch_loss = loss.item()\n",
    "        total_train_loss += batch_loss\n",
    "\n",
    "        # Get sample every x batches.\n",
    "        if step % sample_every == 0 and not step == 0:\n",
    "\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('  Batch {:>5,}  of  {:>5,}. Loss: {:>5,}.   Elapsed: {:}.'.format(step, len(train_dataloader), batch_loss, elapsed))\n",
    "\n",
    "            model.eval()\n",
    "\n",
    "            sample_outputs = model.generate(\n",
    "                                    bos_token_id=random.randint(1,30000),\n",
    "                                    do_sample=True,   \n",
    "                                    top_k=50, \n",
    "                                    max_length = 200,\n",
    "                                    top_p=0.95, \n",
    "                                    num_return_sequences=1\n",
    "                                )\n",
    "            for i, sample_output in enumerate(sample_outputs):\n",
    "                  print(\"{}: {}\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))\n",
    "            \n",
    "            model.train()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)       \n",
    "    \n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epoch took: {:}\".format(training_time))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_labels = batch[0].to(device)\n",
    "        b_masks = batch[1].to(device)\n",
    "        \n",
    "        with torch.no_grad():        \n",
    "\n",
    "            outputs  = model(b_input_ids, \n",
    "#                            token_type_ids=None, \n",
    "                             attention_mask = b_masks,\n",
    "                            labels=b_labels)\n",
    "          \n",
    "            loss = outputs[0]  \n",
    "            \n",
    "        batch_loss = loss.item()\n",
    "        total_eval_loss += batch_loss        \n",
    "\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    \n",
    "    validation_time = format_time(time.time() - t0)    \n",
    "\n",
    "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display floats with two decimal places.\n",
    "pd.set_option('precision', 2)\n",
    "\n",
    "# Create a DataFrame from our training statistics.\n",
    "df_stats = pd.DataFrame(data=training_stats)\n",
    "\n",
    "# Use the 'epoch' as the row index.\n",
    "df_stats = df_stats.set_index('epoch')\n",
    "\n",
    "# A hack to force the column headers to wrap.\n",
    "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
    "\n",
    "# Display the table.\n",
    "df_stats"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPAuhOs6LqPlTbKAiCb1/PW",
   "gpuType": "T4",
   "include_colab_link": true,
   "mount_file_id": "1jdzFQfBomK42CMq2RKVQvVgfODSCiACc",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
