{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/EdmilsonSantana/llm-vehicle-repair/blob/main/Assistente_do_Mecanico_TCC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install selenium beautifulsoup4 datasets transformers[torch] deep-translator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y3w8ud4KIGwQ"
   },
   "source": [
    "## Scraping data from AutoZone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1phBwMcaJ5Bj"
   },
   "source": [
    "We are going to extract the content from the articles found in AutoZone sitemap and finetune the Flan-T5 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "H1Lv23iMJ2oV"
   },
   "outputs": [],
   "source": [
    "from articles import extract_articles\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "AiSf1SGhT1Cg"
   },
   "outputs": [],
   "source": [
    "articles = extract_articles(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "WpSZDH45FwcM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'Car AC Blowing Hot Air', 'content': \"Understanding the Causes\\n\\nA quick understanding of how air conditioning works can help with understanding what the causes could be. When AC is turned on, refrigerant that flows through the system absorbs heat from your vehicle's cabin where it's removed and, through a series of parts and processes, the heat is released into the atmosphere before circulating back and repeating the process. There are several points where something can be wrong, causing warm air rather than cool:\\n\\nThere isn't sufficient airflow in the cabin. This could be a problem with a bad blower motor, but more commonly a plugged cabin air filter is the culprit.\\nThere isn't enough refrigerant. The gas that circulates through the system can leak out, preventing it from working efficiently.\\nThe compressor may not be cycling. A clutch issue or a compressor failure can prevent the AC system from being able to disperse the heat the refrigerant has absorbed.\\nThe expansion valve is clogged. A blockage in the expansion valve could mean cooled refrigerant can't circulate back to the cabin.\\nThe radiator is blocked. Debris blocking the condenser, mounted behind the radiator, could make it impossible for the heated refrigerant to cool effectively.\\nThere's an electrical issue. A number of electrical connections could be loose or damaged, or a part like the HVAC control may not be working well.\\n\\nIf the air from the vents is blowing cool but not cold air, the airflow is weak, the vent temperature goes from hot to cold frequently, or you're only getting warm air from the vents, it's time to give your AC some attention.\\n\\nDIY Diagnosis and Quick Fixes\\n\\nMany AC problems can be identified on your own, and some can be remedied with a quick fix.\\n\\nFirst, check the cabin air filter condition and replace it if it's dirty or clogged.\\nCheck that the heater fan is blowing. If it's only blowing on high speed, the blower motor resistor might be faulty or a fuse might be blown.\\nClean off the radiator. If it's plugged with debris like leaves, dirt, and bugs, wash it off to allow air to pass through it and the condenser.\\nCheck all the wiring connections for the AC system that you can access. There might be a loose connection at the AC compressor, for example. Check along the wires for rubs or cuts.\\nCheck the refrigerant level and top it up. Using a DIY refrigerant kit with a gauge, determine if the system is full or below full. Top up the refrigerant level according to the product's instructions and check the vent temperatures again.\\n\\nRoutine Maintenance Tips\\n\\nRoutine maintenance is essential to ensure your car's air conditioning system continues to blow cool air, especially during warmer months. A simple yet effective maintenance step is routinely checking and replacing the cabin air filter. A dirty or clogged filter can restrict airflow and reduce the system's effectiveness.\\nHaving your air conditioning system professionally inspected at least once a year can help identify potential issues before they lead to significant damage or inefficiency. This inspection should include checking the refrigerant levels and ensuring there are no leaks in the system. Regularly running the AC, even during cooler months, can also prevent seals from drying out and cracking, which can lead to leaks.\\nFurthermore, keeping the car's radiator and condenser clean can prevent overheating and ensure the AC runs efficiently.\\n\\nWhen to Seek Professional Help\\n\\nIf your DIY diagnosis doesn't reveal the problem or you aren't able to conclusively find what's causing the problem, get a professional involved. It's easy to spend a small fortune replacing parts as a guess, and you might still require a visit to the mechanic to get it fixed.\\nWhen you're looking for a repair shop to take your car to, ensure that they have professional-grade equipment to perform AC repairs. Because R134a refrigerant is a controlled material, their technicians need to be certified to recover and recharge your system.\\n\\nPreventative Measures for a Cool Ride\\n\\nTo help avoid AC system problems, keep your engine bay clean, preventing dirt from accumulating on the condenser. As well, make a cabin air filter replacement an annual task right before summer arrives.\\nDuring winter months, use your AC to help defrost the windshield and condition your cabin more effectively. Along with being effective, it can also help you identify if there are issues that need to be addressed before it gets hot outside.\", 'category': 'AC & Climate Control', 'faq_questions': [{'question': 'Why is my car AC blowing hot air?', 'answer': 'There could be a multitude of root causes with common ones being a plugged cabin air filter, bad compressor, clogged expansion valve, or low refrigerant level.'}, {'question': 'Can I fix a hot AC issue myself?', 'answer': \"There are some issues that can be done on your own, while other more involved problems should be addressed by a professional that's certified to handle R134a.\"}, {'question': 'What are the signs of a failing AC compressor?', 'answer': 'Clunking noises when the compressor cycles, intermittent hot and cold air from the vents, and belt squeal are common symptoms of a failing AC compressor.'}, {'question': \"How often should I service my car's AC system?\", 'answer': 'Annually, check that your AC is working properly and change the cabin air filter.'}, {'question': \"When should I consider professional help for my car's AC?\", 'answer': \"If DIY solutions haven't fixed the problem or the repair is more involved than you're ready to tackle, have a professional mechanic work on it for you.\"}]}\n"
     ]
    }
   ],
   "source": [
    "print(articles[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "faq_questions = []\n",
    "for article in articles:\n",
    "    faq_questions.extend(article['faq_questions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "uHlhwY5RUgdV"
   },
   "outputs": [],
   "source": [
    "df_faq = pd.DataFrame(faq_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "v90PQbMdIJIh"
   },
   "outputs": [],
   "source": [
    "has_autozone_text = df_faq['question'].str.contains('AutoZone')\n",
    "df_faq.drop(index=df_faq[has_autozone_text].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Why is my car AC blowing hot air?</td>\n",
       "      <td>There could be a multitude of root causes with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Can I fix a hot AC issue myself?</td>\n",
       "      <td>There are some issues that can be done on your...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What are the signs of a failing AC compressor?</td>\n",
       "      <td>Clunking noises when the compressor cycles, in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How often should I service my car's AC system?</td>\n",
       "      <td>Annually, check that your AC is working proper...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>When should I consider professional help for m...</td>\n",
       "      <td>If DIY solutions haven't fixed the problem or ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0                  Why is my car AC blowing hot air?   \n",
       "1                   Can I fix a hot AC issue myself?   \n",
       "2     What are the signs of a failing AC compressor?   \n",
       "3     How often should I service my car's AC system?   \n",
       "4  When should I consider professional help for m...   \n",
       "\n",
       "                                              answer  \n",
       "0  There could be a multitude of root causes with...  \n",
       "1  There are some issues that can be done on your...  \n",
       "2  Clunking noises when the compressor cycles, in...  \n",
       "3  Annually, check that your AC is working proper...  \n",
       "4  If DIY solutions haven't fixed the problem or ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_faq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1769 entries, 0 to 1782\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   question  1769 non-null   object\n",
      " 1   answer    1769 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 41.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_faq.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning Flan T5 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (3.8.1)\n",
      "Requirement already satisfied: click in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nltk) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nltk) (4.66.2)\n",
      "Requirement already satisfied: datasets in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (2.18.0)\n",
      "Requirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (1.22.4)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (15.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (4.66.2)\n",
      "Requirement already satisfied: xxhash in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets) (2024.2.0)\n",
      "Requirement already satisfied: aiohttp in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (3.9.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (0.21.4)\n",
      "Requirement already satisfied: packaging in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub>=0.19.4->datasets) (4.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas->datasets) (2022.7.1)\n",
      "Requirement already satisfied: six>=1.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: transformers[torch] in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (4.38.2)\n",
      "Requirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers[torch]) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers[torch]) (0.21.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers[torch]) (1.22.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers[torch]) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers[torch]) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers[torch]) (2023.12.25)\n",
      "Requirement already satisfied: requests in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers[torch]) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers[torch]) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers[torch]) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers[torch]) (4.66.2)\n",
      "Requirement already satisfied: torch in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers[torch]) (2.1.2)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers[torch]) (0.28.0)\n",
      "Requirement already satisfied: psutil in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.10.0)\n",
      "Requirement already satisfied: sympy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->transformers[torch]) (1.12)\n",
      "Requirement already satisfied: networkx in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->transformers[torch]) (3.1)\n",
      "Requirement already satisfied: jinja2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->transformers[torch]) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->transformers[torch]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->transformers[torch]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->transformers[torch]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->transformers[torch]) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->transformers[torch]) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->transformers[torch]) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->transformers[torch]) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->transformers[torch]) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->transformers[torch]) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->transformers[torch]) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->transformers[torch]) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->transformers[torch]) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch]) (12.4.99)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->transformers[torch]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->transformers[torch]) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->transformers[torch]) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->transformers[torch]) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sympy->torch->transformers[torch]) (1.3.0)\n",
      "Requirement already satisfied: tokenizers in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (0.15.2)\n",
      "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tokenizers) (0.21.4)\n",
      "Requirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (2024.2.0)\n",
      "Requirement already satisfied: requests in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (4.66.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (4.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (23.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (2024.2.2)\n",
      "Requirement already satisfied: evaluate in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (0.4.1)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from evaluate) (2.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from evaluate) (1.22.4)\n",
      "Requirement already satisfied: dill in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from evaluate) (1.5.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from evaluate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from evaluate) (4.66.2)\n",
      "Requirement already satisfied: xxhash in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from evaluate) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.2.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from evaluate) (0.21.4)\n",
      "Requirement already satisfied: packaging in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from evaluate) (23.2)\n",
      "Requirement already satisfied: responses<0.19 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.13.1)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (15.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
      "Requirement already satisfied: aiohttp in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas->evaluate) (2022.7.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
      "Requirement already satisfied: six>=1.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n",
      "Requirement already satisfied: rouge_score in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (0.1.2)\n",
      "Requirement already satisfied: absl-py in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from rouge_score) (2.1.0)\n",
      "Requirement already satisfied: nltk in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from rouge_score) (3.8.1)\n",
      "Requirement already satisfied: numpy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from rouge_score) (1.22.4)\n",
      "Requirement already satisfied: six>=1.14.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: click in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nltk->rouge_score) (8.1.7)\n",
      "Requirement already satisfied: joblib in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nltk->rouge_score) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nltk->rouge_score) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nltk->rouge_score) (4.66.2)\n",
      "Requirement already satisfied: sentencepiece in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (0.1.99)\n",
      "Requirement already satisfied: huggingface_hub in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (0.21.4)\n",
      "Requirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface_hub) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface_hub) (2024.2.0)\n",
      "Requirement already satisfied: requests in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface_hub) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface_hub) (4.66.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface_hub) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface_hub) (4.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface_hub) (23.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->huggingface_hub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->huggingface_hub) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->huggingface_hub) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->huggingface_hub) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip install nltk\n",
    "pip install datasets\n",
    "pip install transformers[torch]\n",
    "pip install tokenizers\n",
    "pip install evaluate\n",
    "pip install rouge_score\n",
    "pip install sentencepiece\n",
    "pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/utils/generic.py:462: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/utils/generic.py:319: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import T5Tokenizer, DataCollatorForSeq2Seq\n",
    "from transformers import T5ForConditionalGeneration, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from articles import extract_articles\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# Load the tokenizer, model, and data collator\n",
    "MODEL_NAME = \"google/flan-t5-base\"\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(MODEL_NAME)\n",
    "model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME)\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(df_faq)\n",
    "train_test_ds = dataset.train_test_split(test_size=0.2)\n",
    "# We prefix our tasks with \"answer the question\"\n",
    "prefix = \"Please answer this question: \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'answer', '__index_level_0__'],\n",
       "        num_rows: 1415\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'answer', '__index_level_0__'],\n",
       "        num_rows: 354\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "920e0bfc734e4d549f772cd33d65ee9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1415 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bef899104312417eb284b9f1571d2e30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/354 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the preprocessing function\n",
    "\n",
    "def preprocess_function(examples):\n",
    "   \"\"\"Add prefix to the sentences, tokenize the text, and set the labels\"\"\"\n",
    "   # The \"inputs\" are the tokenized answer:\n",
    "   inputs = [prefix + doc for doc in examples[\"question\"]]\n",
    "   model_inputs = tokenizer(inputs, max_length=128, truncation=True)\n",
    "  \n",
    "   # The \"labels\" are the tokenized outputs:\n",
    "   labels = tokenizer(text_target=examples[\"answer\"], \n",
    "                      max_length=512,         \n",
    "                      truncation=True)\n",
    "\n",
    "   model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "   return model_inputs\n",
    "\n",
    "# Map the preprocessing function across our dataset\n",
    "tokenized_dataset = train_test_ds.map(preprocess_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'answer', '__index_level_0__', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1415\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'answer', '__index_level_0__', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 354\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /teamspace/studios/this_studio/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"punkt\")\n",
    "metric = evaluate.load(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "   preds, labels = eval_preds\n",
    "\n",
    "   # decode preds and labels\n",
    "   labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "   decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "   decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "   # rougeLSum expects newline after each sentence\n",
    "   decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "   decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "\n",
    "   result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "  \n",
    "   return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Parameters\n",
    "L_RATE = 3e-4\n",
    "BATCH_SIZE = 8\n",
    "PER_DEVICE_EVAL_BATCH = 4\n",
    "WEIGHT_DECAY = 0.01\n",
    "SAVE_TOTAL_LIM = 3\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "# Set up training arguments\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "   output_dir=\"./results\",\n",
    "   evaluation_strategy=\"epoch\",\n",
    "   learning_rate=L_RATE,\n",
    "   per_device_train_batch_size=BATCH_SIZE,\n",
    "   per_device_eval_batch_size=PER_DEVICE_EVAL_BATCH,\n",
    "   weight_decay=WEIGHT_DECAY,\n",
    "   save_total_limit=SAVE_TOTAL_LIM,\n",
    "   num_train_epochs=NUM_EPOCHS,\n",
    "   predict_with_generate=True,\n",
    "   push_to_hub=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "   model=model,\n",
    "   args=training_args,\n",
    "   train_dataset=tokenized_dataset[\"train\"],\n",
    "   eval_dataset=tokenized_dataset[\"test\"],\n",
    "   tokenizer=tokenizer,\n",
    "   data_collator=data_collator,\n",
    "   compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1770' max='1770' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1770/1770 09:52, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.149851</td>\n",
       "      <td>0.325831</td>\n",
       "      <td>0.135755</td>\n",
       "      <td>0.264907</td>\n",
       "      <td>0.270366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.093176</td>\n",
       "      <td>0.325019</td>\n",
       "      <td>0.133975</td>\n",
       "      <td>0.263560</td>\n",
       "      <td>0.270240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.070600</td>\n",
       "      <td>2.108422</td>\n",
       "      <td>0.320579</td>\n",
       "      <td>0.137358</td>\n",
       "      <td>0.262536</td>\n",
       "      <td>0.268787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.070600</td>\n",
       "      <td>2.157729</td>\n",
       "      <td>0.329891</td>\n",
       "      <td>0.145051</td>\n",
       "      <td>0.272676</td>\n",
       "      <td>0.278419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.070600</td>\n",
       "      <td>2.221337</td>\n",
       "      <td>0.324979</td>\n",
       "      <td>0.140882</td>\n",
       "      <td>0.266297</td>\n",
       "      <td>0.271246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.278700</td>\n",
       "      <td>2.276956</td>\n",
       "      <td>0.324359</td>\n",
       "      <td>0.140910</td>\n",
       "      <td>0.266741</td>\n",
       "      <td>0.271738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.278700</td>\n",
       "      <td>2.402885</td>\n",
       "      <td>0.326588</td>\n",
       "      <td>0.143634</td>\n",
       "      <td>0.269227</td>\n",
       "      <td>0.275727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.278700</td>\n",
       "      <td>2.450764</td>\n",
       "      <td>0.327633</td>\n",
       "      <td>0.144797</td>\n",
       "      <td>0.267569</td>\n",
       "      <td>0.274056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.897400</td>\n",
       "      <td>2.572177</td>\n",
       "      <td>0.322558</td>\n",
       "      <td>0.139045</td>\n",
       "      <td>0.264247</td>\n",
       "      <td>0.270081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.897400</td>\n",
       "      <td>2.615739</td>\n",
       "      <td>0.328173</td>\n",
       "      <td>0.144781</td>\n",
       "      <td>0.268941</td>\n",
       "      <td>0.274802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/generation/utils.py:1178: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/generation/utils.py:1178: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/generation/utils.py:1178: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/generation/utils.py:1178: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1770, training_loss=1.314621032025181, metrics={'train_runtime': 592.9578, 'train_samples_per_second': 23.863, 'train_steps_per_second': 2.985, 'total_flos': 443392422460416.0, 'train_loss': 1.314621032025181, 'epoch': 10.0})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "last_checkpoint = \"./results/checkpoint-1500\"\n",
    "\n",
    "finetuned_model = T5ForConditionalGeneration.from_pretrained(last_checkpoint)\n",
    "tokenizer = T5Tokenizer.from_pretrained(last_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/generation/utils.py:1178: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad>Synthetic blend is more expensive than conventional oil, and it's less durable than conventional oil\n"
     ]
    }
   ],
   "source": [
    "my_question = \"What are the disadvantages of synthetic blend oil?\"\n",
    "inputs = \"Please answer to this question: \" + my_question\n",
    "\n",
    "inputs = tokenizer(inputs, return_tensors=\"pt\")\n",
    "outputs = finetuned_model.generate(**inputs)\n",
    "answer = tokenizer.decode(outputs[0])\n",
    "from textwrap import fill\n",
    "\n",
    "print(fill(answer, width=80))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping \"O Mecnico\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from seaborn) (1.22.4)\n",
      "Requirement already satisfied: pandas>=1.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from seaborn) (1.5.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from seaborn) (3.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.49.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2022.7.1)\n",
      "Requirement already satisfied: six>=1.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mecanico import extract_posts\n",
    "import pandas as pdimport\n",
    "from nltk import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = extract_posts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for post in posts:\n",
    "    sentences.extend(post['sentences'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['15) Com um pano, remova o excesso de graxa.',\n",
       " '16) Localize a trava externa da junta homocintica.',\n",
       " '17) Com o auxlio de um alicate, solte a trava da junta homocintica.',\n",
       " '18) Retire a junta homocintica e a coifa antiga.',\n",
       " '19) Limpe o semieixo e faa uma verificao do estado das estrias e do canal da trava da homocintica.',\n",
       " '20) Neste Chevrolet Celta 2011 foi utilizado o kit VKJA 41000 A, da SKF, que j inclui a homocintica fixa com porca, coifa, abraadeiras, graxa de bissulfeto de molibdnio e manual de montagem. Utilize todos os novos componentes do kit.',\n",
       " '21) Antes de iniciar a montagem da nova homocintica, proteja a extremidade do semieixo com uma fita a fim de evitar rasgos causados pelas estrias no momento da instalao da coifa.',\n",
       " '22) Instale a nova coifa no semieixo e retira a fita utilizada para proteo.',\n",
       " '23) Faa a lubrificao da junta homocintica com a graxa de bissulfeto de molibdnio.',\n",
       " '24) Introduza a junta homocintica no semieixo, observando e certificando-se do correto travamento.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[20:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7fce07582da0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "sentences_lengths = []\n",
    "\n",
    "for sentence in sentences:\n",
    "    tokens = tokenize.word_tokenize(sentence)\n",
    "    sentences_lengths.append(len(tokens))\n",
    "\n",
    "sentences_lengths = np.array(sentences_lengths)\n",
    "\n",
    "sns.displot(sentences_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0014411529223378704"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences_lengths[sentences_lengths > 1024])/len(sentences_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55.60432345876701"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(sentences_lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning GPT-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://colab.research.google.com/drive/13dZVYEOMhXhkXWfvSMVM1TTtUDrT6Aeh?usp=sharing#scrollTo=63t_69HjlwAj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://tuanatran.medium.com/fine-tuning-large-language-model-with-hugging-face-pytorch-adce80dce2ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, RandomSampler, SequentialSampler\n",
    "torch.manual_seed(42)\n",
    "\n",
    "from transformers import GPT2LMHeadModel,  GPT2Tokenizer, GPT2Config, GPT2LMHeadModel\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('pierreguillou/gpt2-small-portuguese', bos_token='<|startoftext|>', eos_token='<|endoftext|>', pad_token='<|pad|>')\n",
    "tokenizer.model_max_length=1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The max model length is 1024 for this model, although the actual embedding size for GPT PT-BR small is 1024\n",
      "The beginning of sequence token <|startoftext|> token has the id 50257\n",
      "The end of sequence token <|endoftext|> has the id 0\n",
      "The padding token <|pad|> has the id 50258\n"
     ]
    }
   ],
   "source": [
    "print(\"The max model length is {} for this model, although the actual embedding size for GPT PT-BR small is 1024\".format(tokenizer.model_max_length))\n",
    "print(\"The beginning of sequence token {} token has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.bos_token_id), tokenizer.bos_token_id))\n",
    "print(\"The end of sequence token {} has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.eos_token_id), tokenizer.eos_token_id))\n",
    "print(\"The padding token {} has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.pad_token_id), tokenizer.pad_token_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT2Dataset(Dataset):\n",
    "\n",
    "  def __init__(self, txt_list, tokenizer, gpt2_type=\"gpt2\", max_length=1024):\n",
    "\n",
    "    self.tokenizer = tokenizer\n",
    "    self.input_ids = []\n",
    "    self.attn_masks = []\n",
    "\n",
    "    for txt in txt_list:\n",
    "\n",
    "      encodings_dict = tokenizer('<|startoftext|>'+ txt + '<|endoftext|>', truncation=True, max_length=max_length, padding=\"max_length\")\n",
    "\n",
    "      self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n",
    "      self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n",
    "    \n",
    "  def __len__(self):\n",
    "    return len(self.input_ids)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    return self.input_ids[idx], self.attn_masks[idx] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16,861 training samples\n",
      "1,874 validation samples\n"
     ]
    }
   ],
   "source": [
    "dataset = GPT2Dataset(sentences, tokenizer, max_length=1024)\n",
    "\n",
    "# Split into training and validation sets\n",
    "train_size = int(0.9 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "print('{:>5,} training samples'.format(train_size))\n",
    "print('{:>5,} validation samples'.format(val_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "# Create the DataLoaders for our training and validation datasets.\n",
    "# We'll take training samples in random order. \n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  # The training samples.\n",
    "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
    "            batch_size = batch_size # Trains with this batch size.\n",
    "        )\n",
    "\n",
    "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the model\n",
    "model = GPT2LMHeadModel.from_pretrained(\"pierreguillou/gpt2-small-portuguese\")\n",
    "\n",
    "# this step is necessary because I've added some tokens (bos_token, etc) to the embeddings\n",
    "# otherwise the tokenizer and model tensors won't match up\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "device = torch.device(\"cuda\")\n",
    "model.cuda()\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some parameters I cooked up that work reasonably well\n",
    "\n",
    "epochs = 5\n",
    "learning_rate = 5e-4\n",
    "warmup_steps = 1e2\n",
    "epsilon = 1e-8\n",
    "\n",
    "# this produces sample output every 100 steps\n",
    "sample_every = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
    "optimizer = AdamW(model.parameters(), lr = learning_rate, eps = epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of training steps is [number of batches] x [number of epochs]. \n",
    "# (Note that this is not the same as the number of training samples).\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "# This changes the learning rate as the training loop progresses\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = warmup_steps, \n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time(elapsed):\n",
    "    return str(datetime.timedelta(seconds=int(round((elapsed)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 5 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   100  of  8,431. Loss: 0.15877652168273926.   Elapsed: 0:00:23.\n",
      "0: Grupo. do disco os destaques so os componentes eltricos e o sistema de limpeza, que pode ser indicado com o equipamento mecnico instalado. O disco  polidos no padro de 2400 L (13.7V). Alm de no ter problema com o desgaste do disco pode ser utilizado a troca de combustvel, pois  recomendado ao uso de motor diesel. Alm disso as especificaes para o disco so idnticas quelas para o sistema eletrnico e com os componentes eltricos o disco  com uma potncia mxima de 150 cv (59 cv de potncia, 5.2 V) com potncia de 100 cv (16 cv, 5.8 V), com cmbio automtico manual, de 3 marchas e cmbio manual, com comando manual (15-T) (5 marchas), cmbio automtico e freios ABS. O disco  feito em linha de montagem do, com injeo eletrnica, de combustvel lquido de 5 litros (2 T), de 0.5 T de Nitro de Na (7.0 N),\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   200  of  8,431. Loss: 0.15369173884391785.   Elapsed: 0:00:49.\n",
      "0: trio e a sua localizao na estrada. Aps ter sido retirada na sua volta, passou o teste do veculo (16/12/2018) de apoio que ficou sem problema. (ADMU)  o sistema de freio automtico do veculo que determina a posio do cilindro.  utilizado para o aumento do cmbio dianteiro e de troca. O sistema est indicado por uma chave de ignio e  utilizado na carcaa, quando as vlvulas esto em funcionamento. O modelo 1D de 70 mm (18 mm atrs do cilindro) est indicado. Esse sistema est indicado no veculo (18 mm atrs do cilindro). O motor do carro possui as marchas em marcha constante (12v) e cmbio automtico, a indicao  12 CV. Quando o combustvel est em aplique, a vlvula tambm  acionado, quando possui a chave de ignio. Essa chave tambm  utilizada nas trocas e na transmisso (18 mm atrs do cilindro) na transmisso (18 mm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   300  of  8,431. Loss: 0.2308550328016281.   Elapsed: 0:01:14.\n",
      "0: nos do sistema, com o qual a chave do mdulo de comando  o mesmo da chave da cabine.  um sistema eltrico, desenvolvido pela unidade de transporte de nibus de todo o Brasil para nibus de carga em nibus urbano. Com o auxlio do veculo de alta performance nibus, a diferena na utilizao de combustvel e nas condies de uso entre os veculos  de 40% (54) a 40% (30) do custo do veculo de carga. O sistema  dotado de trs baterias, a saber: um por cilindro, um por cilindro e um por cilindro de dupla plaqueta.\n",
      "O sistema vem sendo utilizado desde meados do sculo XX pelos nibus que realizam a manuteno de nibus, tanto para nibus de carga quanto para nibus urbano. O nibus do tipo nibus urbano tambm vem sendo usados na manuteno de outros veculos, como nibus de nibus diesel, nibus urbano e nibus de nibus ABS. O sistema foi desenvolvido na prpria linha da nibus nibus da Fiat entre 2003 e 2005,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   400  of  8,431. Loss: 0.39087721705436707.   Elapsed: 0:01:39.\n",
      "0:  along,  uma cidade da regio do vale do Rio das Bocas, localizada entre a cidade de So Bernardo de Campo a So Bernardo do Campo, e So Bernardo do Campo-SP. Tambm conhecida como Porto Alegre ou Porto Alegre,  uma cidade com um pouco mais de 30 anos de histria, sendo que j esto entre os mais importantes plos do estado e tambm um dos mais importantes centros de servios de qualidade do Brasil. Entre as muitas funes de direo do sistema de arrefecimento e da bomba dgua, Porto Alegre possui a responsabilidade das respectivas unidades eltricas e de sistema de transmisso de leo, com um papel cada vez mais importantes. Vale ressaltar que o sistema de troca de leo  a base do sistema de troca de leo-pirlise aplicado no sistema hidrulico do motor.  um modelo do tipo Peugeot Eaton, utilizado na marca da Honda. Ele foi o primeiro veculo da Honda a ter um cmbio interno no mercado na verso\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   500  of  8,431. Loss: 0.45087066292762756.   Elapsed: 0:02:04.\n",
      "0: : Soldas/2-3\n",
      "Drive 8000 vezes no mximo. A Naisulis do  Sone, A reportagem da reportagem tem como ponto de referncia os pontos de referncia para este processo na produo de um lquido refrigerante. (OUT)  Com 13 anos de histria e 12 prmios, esta cidade do Mxico possui a quinta posio da IUMOM e ainda em primeiro. Na comparao, o Brasil ocupa primeiro lugar, atrs de So Paulo (11 lugar entre os principais). A cidade tem uma economia,  bem formada com vrios tipos de servios: o sistema de energia, o papel de servios no-utilizados no\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   600  of  8,431. Loss: 0.11235810071229935.   Elapsed: 0:02:29.\n",
      "0:  blocoO mecnico no  o nico a prestar servio aos clientes do carro. Antes da instalao do sensor de ABS, os veculos da cidade de So Paulo j tinham problemas com sua vida til. O filtro no possui filtros para a corrente de baixa presso, que  responsvel pela perda de vida de combustvel. So os filtros que o veculo utiliza. Antes de instalao,  preciso tomar cuidado com o fluxo de ar do filtro e verificar que a sua aplicao  normal, o que permite que ele no seja interrompida. O filtro tem o objetivo de no agredir o motor e provocar acidentes, alerta o gerente Comercial da Bosch Automotive Co. O filtro  responsvel pelo abastecimento do fluido de poluentes do ar e tambm,  responsvel por o balano de potncia de baixa presso da bomba de ar. mangueiras do\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   700  of  8,431. Loss: 0.4397437274456024.   Elapsed: 0:02:54.\n",
      "0: 89 de entrada do sistema. Neste caso a presso ocorre na entrada, enquanto os resduos do sistema so filtradores.  um servio de alta tecnologia da Shell que recebe, em mdia, 1,030 MW, capaz de entregar a emisso de alta potncia do motor, com potncia de 240 cv, ou 4 kgfm ou 5,0 kgfm de torque mximo mximo mximo que seja a potncia obtida por motor. Por fim, o programa possui fcil substituio de componentes, j que o motor est sujeito  sua reviso sem a correo por meio da recomendao de diagnstico do profissional. O veculo  dividido em uma unidade de injeo de combustvel e um motor-leve e tem em sua bancada a caixa de transferncia da bomba de alta presso, comenta Alexandre Vilmar de A. KYBB.  Ele tambm alerta sobre a possibilidade de no-conversao no comando do motor quando a correia hidrulica de freio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   800  of  8,431. Loss: 0.23727595806121826.   Elapsed: 0:03:19.\n",
      "0: isc: o mecnico no pode retirar o conjunto, mas o carro sempre est funcionando, sempre no elevador de alta velocidade e  legal que a tubulao esteja no seu acesso.  bom lembrar que o carro est em uso no momento do funcionamento normal, ou seja, uma vez que o motor est parado e a potncia e a potncia esto totalmente na mesma. Mas se voc remover a tubulao, o motor pode no funcionar at a bomba dgua, se voc no reinstalar o conjunto e o carro ser parada. O carro estava totalmente parado, s h a possibilidade de ele parar ou pegar numa bateria. Se ele ficar parado e o carro vai parar em seguida a bomba dgua vai dar continuidade, j que o motor est totalmente funcionando. Ele sempre est, mas o carro j estava parado. Se a bomba dgua no for removido, pode causar perda de potncia.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   900  of  8,431. Loss: 0.41053807735443115.   Elapsed: 0:03:44.\n",
      "0:  negociadoCom os amortecedores nas ruas, foram incorporadas os conjuntos de amortecedores convencionais. A manuteno em estradas de estradas fechadas  uma grande importncia, j que em caso de uso severo, pode danificar o cabeote da torre de suspenso, possibilitando ao amortecedor a perder sua posio. Para no forar a torre de suspenso, basta fazer uma inspeo.  Traque o tensionador de freio, que  instalado em um volante para atestar se  necessrio remover o tensionador do freio.    importante lembrar que a pea deve ter sido aplicada em todas as suas etapas, no s no centro, mas em todas as faces do veculo. (A.M.C)  um mecnico mecnico de componentes do Brasil e proprietrio de uma oficina de montagem que fabrica cerca de 30 produtos no mercado internacional, dos quais cerca de 1,8 mil so fabricados pela Bosch. A montagem segue a linha da Ford (R7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1,000  of  8,431. Loss: 0.10827979445457458.   Elapsed: 0:04:09.\n",
      "0:  prticaA montagem segue os mesmos padro da suspenso dianteira, por isso, as peas so de fcil reparabilidade. O tensionador  acionado por uma chave combinada 17 mm (1,5 mm do primeiro cilindro) e o coletor de admisso j vem alinhado. A correia est de um comprimento de 15 mm com uma funo de regulagem da bomba de escape para atender o torque de aperto, que  de 6,2 Nm (1,5 a 5,4 mm de torque). (SKD)  um servio de informaes e informaes a base de informaes relacionados ao veculo e  linha de veculos, atravs do fabricante e pela fabricante de produtos, na Amrica do Sul. Seu proprietrio fica localizado no Valeo, em Valinhos- RJ. O catlogo de produtos do servio  baseado nos mapas de manuteno do Peugeot 206 e Citron C3 S10. (28 de junho de 2007)  um tcnico de\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1,100  of  8,431. Loss: 0.2522244155406952.   Elapsed: 0:04:34.\n",
      "0:  QuirImotivo de ar, ou ar condicionado, tambm conhecido como ar do motor, est localizado no cabeote superior dos pneus, no compartimento do reservatrio, no compartimento de apoio para o motor, com caixa de cmbio, sistema ABS, e motor embreagem. Sua funo  garantir a estabilidade e o funcionamento de todo o conjunto, independentemente de um veculo ou veculo em estrada urbano. O funcionamento do sistema  feito a cada 20 mil quilmetros. da Revista O Mecnico teve um acidente no trnsito rodovirio nacional em pleno trnsito e foi possvel observar um pequeno incidente com trnsito urbano em todo o pas e, consequentemente, com o veculo. Porm, o acidente nem sempre foi um problema crnicos que nem sempre foi aparente. Porm, os problemas de trnsito podem existir na parte traseira do veculo, no lado esquerdo do veculo (no lado direito da traseira do acelerador), em outros carros e em ruas, como a picape. E no se esquea de utilizar o acelerador para\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1,200  of  8,431. Loss: 0.43338391184806824.   Elapsed: 0:04:59.\n",
      "0:  Foster8) Inicie a torre de suspenso do motor para ter acesso ao bloco: a montagem do bloco deve ser feita por diversos fatores. Por isso, o principal que deve ser feito  um sistema mais simples com mais facilidade para manuteno e com maior durabilidade. Se o bloco for removido dentro da instalao de manuteno, o motor precisar de ferramentas especiais para a desmontagem e manuteno correto. Na mesma hora, utilize uma chave Allen de emergncia., que  o coordenador de treinamento do programa de treinamento do Instituto Ford, em Valinhos, SP, levou o evento para a imprensa, onde o proprietrio do sistema de sincronismo da empresa levou a seguinte observao:  imperativo ter acesso aos componentes que podem facilitar o desempenho de um carro no trnsito urbano, afirma. (5 de junho de 2013)  uma das sondas mais antigas que j foram aprovadas por uma grande imprensa do setor com foco em auxiliar a manter a tecnologia em dia. E, de\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1,300  of  8,431. Loss: 0.06648953258991241.   Elapsed: 0:05:24.\n",
      "0:  Santssimo.   Brasil Brasil | Brasil | Al Brasil | Brasil | Al Brasil | Al Brasil | Al Brasil | Al Brasil | Al Brasil | Al Brasil | Al Brasil | Al Brasil | Al Brasil | Al Brasil | Al Brasil | Al Brasil | Al Brasil | Al Brasil | Al Brasil | Al Brasil | Al Brasil | Al Brasil | Al Brasil | Al Brasil | Al Brasil | Al Brasil | Al Brasil | Al Brasil | Al Brasil | Al Brasil | Al Brasil | Al Brasil | Al Brasil | Al Brasil | Al Brasil | Al Brasil | E, T, E,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1,400  of  8,431. Loss: 0.20496244728565216.   Elapsed: 0:05:49.\n",
      "0:  repleAcompanhe agora os modelos: Volkswagen Spin Pack, Volkswagen TRO, Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller Troller\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1,500  of  8,431. Loss: 0.3214110732078552.   Elapsed: 0:06:14.\n",
      "0:  aband7- Remova o sincronizador e retire o leo, que  fixado com trava. O leo foi fabricado com fbrica italiana, o motor E.torQ2001-B, que segue a mesmas regra de manuteno do motor E.torQ2001-B (3). Aspecto: 8606907 O Mecnico O Mecnico  Communal   Aspecto: 86069077, Aspecto: 8606907, 2017, teve o desempenho melhor do modelo desde a estreia dos motores do Gol, com 2.200cv a menos em relao a outros motores da Ford. Por baixo, as verses de 8606907 de fbrica so quatro cilindros.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1,600  of  8,431. Loss: 0.04926364868879318.   Elapsed: 0:06:39.\n",
      "0:  Borgonha Solte os parafusos de fixao da correia dentada e a junta de fixao da junta de fixao da junta com um martelo., conhecido popularmente como Zleo do virabrequim, est localizado na regio do coletor de escapamento. Faz a sada da turbina e os terminais da conexo com o filtro de ar de admisso. Por cima, a bateria fica localizada., conhecido popularmente como Zleo do virabrequim, est localizado na regio do coletor de escapamento. Por cima, a bateria fica localizada., conhecido popularmente como Zleo do virabrequim  um item muito popular entre o mecnico e o mecnico profissional. O item  um utilitrio de srie, mas sem perder o ponto., conhecido popularmente como Zleo do virabrequim, est localizado em um local\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1,700  of  8,431. Loss: 0.39272335171699524.   Elapsed: 0:07:04.\n",
      "0:  ModNa montagem, no se esquecer de engatar uma sonda lambda de alta presso para que a sonda lambda possa ser trocada, com o auxlio de um martelo para solt-la. Lembre-se que o torque final da pea  de 55.750 rpm e o torque final da sonda lambda estar em torno de 50.000 rpm. Neste caso, observe o torque final do parafuso de cabea para baixo: de 50.000 rpm e em torno de 60.000 rpm. Depois, utilize uma chave L12 mm para soltar a sonda. Na montagem, o torque final da sonda lambda  de 27.000 rpm e a mesma foi trocada com o auxlio de um martelo. com injeo por ar (COMO: 4.5) com capacidade para receber 6.000 (COMO: 35)itro de potncia, com fcil acesso  fixao do suporte de sustentao. A injeo  automtica de trs estgios\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1,800  of  8,431. Loss: 0.19349679350852966.   Elapsed: 0:07:29.\n",
      "0: cos6. A primeira etapa de montagem da pea  na seqncia: Todo este conjunto  construdo por profissionais da Michelin em parceria com a General Motors, e sua oficina  ligada ao mecnico, responsvel por manter o nvel de leo e temperatura do fluido de freio da sua oficina. Quando o motor estiver no cho com a roda suspensa, o turbo  o responsvel pela manuteno do sistema hidrulico e, se estiver suspenso e no estiver mais, o turbo  o responsvel pelo diagnstico dos componentes do sistema de alta presso. O turbo tem que ser acionado por parte dacionaro do motor com o pedal parado e o turbo, que  o ltimo componente, no  capaz de manter a eficincia do seu movimento, fazendo com que o carro se coloque o leo. O mecnico pode escolher um outro, dependendo da condio de uso, alerta.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1,900  of  8,431. Loss: 0.27877697348594666.   Elapsed: 0:07:54.\n",
      "0: m13) Remova os parafusos de fixao da correia elstica que fixam a correia por fixado no cavalete, utilizando a chave L 13 mm (13a). Remova o tensionador de fixao do virabrequim, que  para cima (13b). Depois, remova a correia elstica do lado direito e aperte o parafuso de fixao do parafuso. (22) (45) Com o auxlio de Gustavo Lalli, o painel de confirmao dos modelos com as sondas lambdas do INS, assim como o procedimento completo de substituio dos componentes do veculo,  considerado o momento certo da substituio. (19) e o painel de fotos de Marcelo Caretta a ser seguido foram apresentados nas apresentao do painel. Depois de analisar a estrutura dos veculos, Roberto Santos, diretor de Novos Negcios da ZF, e Andr Haddad, consultor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 2,000  of  8,431. Loss: 0.20327818393707275.   Elapsed: 0:08:19.\n",
      "0: anas6. Com o conjunto do conjunto, aplique uma medida na sequncia e faa o ajuste correto pelo circuito de alimentao da correia. O circuito vai para o coletor, prximo  polia, gerando uma medida na medio da tenso do coletor, evitando que ele fique cheio ou com nenhuma tenso. A tenso do coletor deve ser fixada em um valor maior que a unidade de carga, com que a tenso seja reduzida. A tenso de aperto, por causa de sua natureza diferente, vai causar baixa resistncia, baixa carga, baixo desempenho ou consumo de energia. Evite que um veculo caia. Mais informaes:  Mais informaes:  Mais informaes:   Mais informaes:  Mais informaes:  Mais informaes:  Mais informaes:  Mais informaes: Mais informaes:   Mais informaes:   Mais informaes:  Mais informaes:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 2,100  of  8,431. Loss: 0.34851017594337463.   Elapsed: 0:08:44.\n",
      "0: illeA substituio do tensor de fora  feita de forma progressiva, se houver, seguindo a indicaes da fabricante e os componentes de suspenso para que se reinstale no veculo. Como esse tipo de processo de reduo das presses no sistema, h algum momento, quando um determinado pneu sofre muita rotao irregular, o tcnico do SENAI-Vila Leopoldina, Edivaldo Codlio,  recomendado. O Civic Civic Civic GNV  um Civic Civic com motor 1.5 2.0 lp de potncia com 8,2 rpm, de 4,7 rpm, em duas verses: a verso 1.6  trao 4 velocidades, e a verso 2.5  4 velocidades  com motor 2.0 1.6 lp de potncia, com 8,3 km rodados  no deve!               \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 2,200  of  8,431. Loss: 0.2972087264060974.   Elapsed: 0:09:09.\n",
      "0:  encontrava11) Com o amortecedor ainda instalado, retire o conjunto e passe at o cavalete. Remova agora o conjunto. Depois de apertar o coxim com chave, solte a porca de fixao do amortecedor e aplique o torque mximo de 10 Nm. O O A barra estabilizadora do motor 2.0 de potncia com leo lubrificante de 5W20. A primeira troca de leo do motor a ser feita com aditivos de m qualidade e com viscosidade superior a 50 Nm  realizada por Matheus, diretor de Assistncia Tcnica da Valeo. Emanoel Nakata, localizada na parte externa do  Acompanhe a situao do espao de arrefecimento\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 2,300  of  8,431. Loss: 0.14090704917907715.   Elapsed: 0:09:34.\n",
      "0: cis3) Aps remover a nova tampa de vlvulas, remova a porca da flange da flange. Substitua a porca com a braadeira. (11) (11) (11) (11)    Na figura 4,  possvel ver que h alguns rasgos gastos no alojamento do filtro de leo que so vendidos como um todo. No se trata apenas de um crter, mas tambm uma vlvula termosttica.  feita por duas velas de calor, e o combustvel est dentro da vlvula termosttica. Se for reutilizada por uma pea ou por uma vlvula termosttica, no  necessrio desmontar os cabos. Por isso,  comum a ser trocada. Se necessrio,  possvel ser reinstalada no filtro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 2,400  of  8,431. Loss: 0.2483583688735962.   Elapsed: 0:09:59.\n",
      "0:  colisoCausa provvel: Entrega em que no existe, quando o conjunto de freios  danificado. (11) Ateno:  possvel a troca de dois parafusos do eixo traseiro para a fixao (11). (11) O Mecnico (11)  um mecnico mecnico de automveis que trabalha para a Revista O Mecnico e ao revistas O Mecnico e O Mecnico. O mecnico  responsvel pela manuteno do cmbio dianteiro da Toyota Corolla, ano 2007, o cmbio CVT  o de uso severo, com uma faixa de substituio rpida,  o que tem a funo de diminuir a consumo de combustvel.  possvel acessar os pneus em caminhes com rodas com menos atrito e, consequentemente, menos espao. (11) O Denox  um componente eletrnico que possui funo de movimentar a capa protetora ou proteo protetora do amortecedor (11). O componente precisa do\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 2,500  of  8,431. Loss: 0.25178205966949463.   Elapsed: 0:10:24.\n",
      "0: sEm relao  utilizao de tecnologias remanufaturadas, a Bosch explica que no h normas para adaptar a verso em veculos comerciais no mercado de motores e no existem normas para adaptar a bomba hidrulica com motores mais modernos.  muito comum fazer a converso entre a bomba hidrulica de 3 cilindros, o que no  possvel para se fazer no sistema da vlvula de reteno do ar-condicionado. O (2023)  O procedimento de troca preventiva e completo das vlvulas  a principal parte da manuteno do sistema do motor 1.0, que tem duas vlvulas (1.0 E.torQ1.0), trs marchas, duas transmisso e 2.0 e dois em dupla com a mesma vlvula. O manual do proprietrio afirma o procedimento foi feito com sucesso. (2023)  o nome\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 2,600  of  8,431. Loss: 0.1293887346982956.   Elapsed: 0:10:49.\n",
      "0:  Sorocaba4) Veja o estado do sensor de rotao, que fica prximo a o eletro-guia do sensor, onde est representado, e onde  armazenado o material utilizado na placa de leitura. Utilize uma chave de fenda que  acionada por dois parafusos, um e a outra. O Mecnico Soluo da troca Motorista (2013) Motorista  um dos principais marcas comerciais do Brasil. Suas sedes esto na capital e o seu objetivo  fazer todo o possvel para fazer o seu cliente, seja proprietrio, proprietrio da montadora, proprietrio do caminho e proprietrio da oficina. Apesar de ser um empresa, o mecnico e proprietrio de veculos comerciais, foi proprietrio e proprietrio do Grupo Amrica Latina, que comercializa o lcool e a mistura para atender as\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 2,700  of  8,431. Loss: 0.05410550534725189.   Elapsed: 0:11:14.\n",
      "0: rianA suspenso dianteira  McPherson, mas o cmbio  hidrulico. A direo  manual (1 gerao), fazendo com que a parte dianteira seja automtica. As laterais devem estar completamente assentadas na roda. A suspenso dianteira  mecnica (com amortecedores de 6 para cima ou 3 gerao), e a direo  feita por cabos no conjunto (1 gerao).O (11) (11)  No esquea de utilizar o lquido de arrefecimento no intervalo especificado pelo fabricante  a KUO (KWA)  recomendada pela FPTF (Associao Nacional das Fabricantes de Servios Automotivos) e no pelo ASEI (Associao Nacional da Fabricantes de Servios Automotivos).   Obs: Em\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 2,800  of  8,431. Loss: 0.2752264440059662.   Elapsed: 0:11:39.\n",
      "0:  Wor8) A pea possui uma extenso de aproximadamente 2.100 vezes, portanto  possvel colocar uma pea com um dimetro maior do que a necessria, de 5.496mm. (11) foi o escolhido pela bateria, que faz parte do componente, mas  mais leve. Agora, h mais espao (8). (12) foi o escolhido pela bateria, que faz parte do componente, mas no  mais leve. Agora, h mais espao (8). (13)  o prximo carro do veculo Fiat Cronos CVT e tem fcil substituio. Afinal, o modelo tinha que correr, mas o mecnico tinha que aprender. (14)  um dos componentes automotivos mais importantes da oficina de nibus.  o sistema de distribuio mais complexo das linhas Peugeot e Saveiro (15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 2,900  of  8,431. Loss: 0.1522243618965149.   Elapsed: 0:12:04.\n",
      "0:  desporAo conectar os cabos de partida de ar no volante, o equipamento deve estar em posio segura, prximo ao quadro do motor de partida, prximo ao coletor de escapamento. Para isso, solte os parafusos da fixao inferior da bobina auxiliar. Os parafusos que fixam os conectores com a proteo, o guarda-p, a bandeja, os anis, as polias, os bielas, os roletas, o rolamento, as arruelas e o rolamento esto sem travamento.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 3,000  of  8,431. Loss: 0.34806424379348755.   Elapsed: 0:12:29.\n",
      "0:  Fen2) Remova a correia sincronizadora com o comando de vlvulas. Remova o coletor de combustvel.  uma plataforma do tipo dupla-eixo, que utiliza como referncia o sistema de ignio (7), mas que utiliza uma vela de ignio diferente, com uma ponta ou outra de vela. No seu interior, a correia  conectada eletricamente eletricamente e s tem um cabo. A presso gerada por ela  controlada por um equipamento eletrnico; ela se encontra pelo mdulo eletrnico de cada motor. Numerao de vlvulas (conhecido como oring)  uma plataforma da correia sincronizadora que utiliza um chicote de ignio com uma agulha e uma ponta da agulha, sendo responsvel pelas emisses de combustvel. No seu interior,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 3,100  of  8,431. Loss: 0.043352361768484116.   Elapsed: 0:12:54.\n",
      "0: cabeO primeiro passo para remover essa correia sincronizadora da transmisso manual  remover o garfo superior. Oco da Mahle Soluo: Soltar o motor Nneoscpio \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 3,200  of  8,431. Loss: 0.25971174240112305.   Elapsed: 0:13:19.\n",
      "0:  (...)4) Antes de remover a vlvula de admisso,  possvel tirar dois parafusos fixados por parafusos na caixa seca: uma por cima e outra por baixo. No, deixe o eixo do volante sempre dentro do cilindro-mestre.  um carro da marca francesas Peugeot Citron na categoria heater e que equipa o Renegade, em especificao do Citron C3. O nome vem do sistema de injeo de combustvel que equipa o modelo Peugeot 208, que equipa o hatch hatch. O projeto , mas, sim, utilizado por uma verso, o tipo heater do motor (4A).  um dos veculos com motor 1.4 GSR4 com turbocompressor turbocompressor de 105 cv.  equipado com sistema de alimentao direta direta (4b), com\n"
     ]
    }
   ],
   "source": [
    "total_t0 = time.time()\n",
    "\n",
    "training_stats = []\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "for epoch_i in range(0, epochs):\n",
    "\n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    total_train_loss = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_labels = batch[0].to(device)\n",
    "        b_masks = batch[1].to(device)\n",
    "\n",
    "        model.zero_grad()        \n",
    "\n",
    "        outputs = model(  b_input_ids,\n",
    "                          labels=b_labels, \n",
    "                          attention_mask = b_masks,\n",
    "                          token_type_ids=None\n",
    "                        )\n",
    "\n",
    "        loss = outputs[0]  \n",
    "\n",
    "        batch_loss = loss.item()\n",
    "        total_train_loss += batch_loss\n",
    "\n",
    "        # Get sample every x batches.\n",
    "        if step % sample_every == 0 and not step == 0:\n",
    "\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('  Batch {:>5,}  of  {:>5,}. Loss: {:>5,}.   Elapsed: {:}.'.format(step, len(train_dataloader), batch_loss, elapsed))\n",
    "\n",
    "            model.eval()\n",
    "\n",
    "            sample_outputs = model.generate(\n",
    "                                    bos_token_id=random.randint(1,30000),\n",
    "                                    do_sample=True,   \n",
    "                                    top_k=50, \n",
    "                                    max_length = 200,\n",
    "                                    top_p=0.95, \n",
    "                                    num_return_sequences=1\n",
    "                                )\n",
    "            for i, sample_output in enumerate(sample_outputs):\n",
    "                  print(\"{}: {}\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))\n",
    "            \n",
    "            model.train()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)       \n",
    "    \n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epoch took: {:}\".format(training_time))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_labels = batch[0].to(device)\n",
    "        b_masks = batch[1].to(device)\n",
    "        \n",
    "        with torch.no_grad():        \n",
    "\n",
    "            outputs  = model(b_input_ids, \n",
    "#                            token_type_ids=None, \n",
    "                             attention_mask = b_masks,\n",
    "                            labels=b_labels)\n",
    "          \n",
    "            loss = outputs[0]  \n",
    "            \n",
    "        batch_loss = loss.item()\n",
    "        total_eval_loss += batch_loss        \n",
    "\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    \n",
    "    validation_time = format_time(time.time() - t0)    \n",
    "\n",
    "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display floats with two decimal places.\n",
    "pd.set_option('precision', 2)\n",
    "\n",
    "# Create a DataFrame from our training statistics.\n",
    "df_stats = pd.DataFrame(data=training_stats)\n",
    "\n",
    "# Use the 'epoch' as the row index.\n",
    "df_stats = df_stats.set_index('epoch')\n",
    "\n",
    "# A hack to force the column headers to wrap.\n",
    "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
    "\n",
    "# Display the table.\n",
    "df_stats"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPAuhOs6LqPlTbKAiCb1/PW",
   "gpuType": "T4",
   "include_colab_link": true,
   "mount_file_id": "1jdzFQfBomK42CMq2RKVQvVgfODSCiACc",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
